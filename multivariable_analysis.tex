\documentclass[12pt]{article}
\usepackage{amsfonts, amsthm, amsmath}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{pb-diagram}
\usepackage{hyperref}
\usepackage{cancel}

\setlength{\textwidth}{6.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\textheight}{9.5in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\parskip}{0pt}
\setlength{\parindent}{0pt}



\def\CC{\mathbb{C}}
\def\MM{\mathbb{M}}
\def\FF{\mathbb{F}}
\def\PP{\mathbb{P}}
\def\QQ{\mathbb{Q}}
\def\RR{\mathbb{R}}
\def\ZZ{\mathbb{Z}}
\def\gotha{\mathfrak{a}}
\def\gothb{\mathfrak{b}}
\def\gothm{\mathfrak{m}}
\def\gotho{\mathfrak{o}}
\def\gothp{\mathfrak{p}}
\def\gothq{\mathfrak{q}}
\DeclareMathOperator{\disc}{Disc}
\DeclareMathOperator{\Gal}{Gal}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Norm}{Norm}
\DeclareMathOperator{\Trace}{Trace}
\DeclareMathOperator{\Cl}{Cl}

\def\head#1{\medskip \noindent \textbf{#1}.}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem*{note}{Note}
\newtheorem*{remark}{Remark}
\newtheorem*{claim}{Claim}



\begin{document}
\title{Multivariate Analysis}
\author{Iannis Petridis}
\date{Autum 2011}
\maketitle

\tableofcontents
\setcounter{tocdepth}{4}
\newpage

\section{Mulivarible  Calculus}
\subsection{Notation}
$X\in\RR^{n}$, $ X=\{x_{1},x_{2},\dots,x_{n}\}$ where $x_{i}\in\RR$
$\RR^{n}$ is a vector space\\
length norm$|x|=\sqrt{x_1^2 + x_2^2 + \dots +x_n^2 }$\\
If $Y,X\in\RR^{n}$ and $ Y=\{y_{1},y_{2},\dots,y_{n}\}$ then $X \cdot Y=x_{1}y_{1}+ x_{2}y_{2} +\dots + x_{n}y_{n}$\\
Standard Basis:
\begin{align*}
  e_j=(0, \dots &,  0, 1, 0, \dots)\\
& \textrm{ \scriptsize j-1,\: j, \:j+1} 
\end{align*}
Properties of norm
\[|x|\geq0\]
\[|x|=0  \Leftrightarrow x=\vec{0}\]
\[| \lambda x| = | \lambda| \cdot |x| , \quad x \in \RR^n, \quad \lambda \in \RR \]

\textbf{linear Transformation}
\[T:\RR^{n}\rightarrow\RR^{n}\]
\begin{enumerate}[(i)]
\item $ T(x+y)=T(x) + T(y)$
\item $T(\lambda x) =\lambda T(x) $
\end{enumerate}
Matrix Representation of T with respect to the standard basis:\\
\[T(e_i)=\sum_{j=1}^{m}a_{i,j}e_j \textrm{ where } [T]_{\epsilon}^{\epsilon}=A=(a_i,j)_{\substack{i=1,\dots ,m \\ j=1,\dots ,n}}\]

Given: $T:\RR^{n}\rightarrow\RR^{m}, S:\RR^{n}\rightarrow\RR^{m} \textrm{ and } U:\RR^{m}\rightarrow\RR^{k}$
\begin{enumerate}[(i)]
\item $ [UT]_{kxm}=[U]_{kxm}[T]_{mxn}$
\item $[T+S]=[T]+[S]$
\item $\lambda[T]=[\lambda T]$
\end{enumerate}
$T:\RR^{n}\rightarrow\RR^{m}, X\in \RR^{n}, Y\in \RR^{m}, X=(x^{1},\dots ,x^{n}), Y=(y^{1},\dots ,y^{m})$\\
\[  \left(\! \begin{array}{c} y^{1} \\ y^{2}\\ \vdots\\ y^{m} \end{array}\! \right) = [T] \left(\! \begin{array}{c} x^{1} \\ x^{2}\\ \vdots\\ x^{n} \end{array}\! \right) \]

\subsection{Functions \& Continuity}
$f:\RR^{n} \rightarrow\RR^{m}$ vector valued function\\
$f:A \rightarrow\RR^{m}$ where $A \subset \RR^{n}$\\
then $f$ has components which are scalar fields.\\
$ f^{i}:A \rightarrow\RR$\\
\[f(x)=(f^{1} (x),\dots ,f^{m}(x))\] 

$\Pi^{i}:\RR^{m}\rightarrow\RR $
\[\Pi^{i}((x)^{1},\dots ,(x)^{m})\]
$\Pi^{i}$ is a linear transformation for i=1,$\dots$,m\\

\[
\begin{diagram}
\node{\RR^{n}} \arrow{e,t}{f}  \arrow{se,b}{f^{i}}
\node{\RR^m}  \arrow{s,r}{\Pi^{i}} \\
 \node[2]{\RR}
\end{diagram}
\]

\begin{definition}
$f:\RR^{n} \rightarrow \RR^{m}$ then 
$\lim_{x\to a} (f(x))=b$ means:
\[
\forall \epsilon > 0, \exists \delta > 0 \; st,\; 
0<|x-a|<\delta \Rightarrow |f(x)-b|<\epsilon\] 
\end{definition}

\begin{definition}
$f$ is called continuious at a if:
\[\lim_{x\to a} (f(x))=f(a)\]
$f$ is called continuious at the set of A if it is continuious at a $\forall a \in A$l
\end{definition}

\begin{theorem}[Combination Theorm]\label{T:Combination Theorm}
Assume \[\lim_{x\to a} (f(x))=b, lim_{x\to a} (g(x))=c\]
then:
\begin{enumerate}[(i)]
\item$\lim_{x\to a} (f(x) + g(x))=b+c$
\item$\lim_{x\to a} (\lambda f(x))=\lambda b$
\item$\lim_{x\to a} (f(x)\cdot g(x))=b\cdot c$
\item$\lim_{x\to a} |f(x)|=|b|$
\end{enumerate}
\begin{proof}
of (iii)
\begin{align*}
f(x)\cdot g(x)-b\cdot c &= f(x)\cdot g(x) -b\cdot g(x) + b\cdot g(x) -b\cdot c \\
&= g(x)\dot (f(x)-b) + b\cdot (g(x) - c) \\
|f(x)\cdot g(x)-b\cdot c|&= |g(x)\dot (f(x)-b) + b\cdot (g(x) - c)|\\
 &\leq |g(x)\dot (f(x)-b)| +| b\cdot (g(x) - c)|\\
\end{align*}
Cauchy-Schwartz: $|x^{1}y^{1} + \dots +x^{n}y^{n}| \leq \sqrt{(x^{1})^{2} + \dots +(x^{n})^{2}} \cdot \sqrt{(y^{1})^{2} + \dots +(y^{n})^{2}}$
\[|f(x)\cdot g(x)-b\cdot c| \leq |g(x)\dot (f(x)-b)| +| b\cdot (g(x) - c)|  \leq |g(x)|\cdot |f(x)-b| +|b|\cdot |g(x) - c|\]
Since $ lim_{x\to a} (g(x))=c$, $g$ is a bounded neighbourhood of a, i.e: 
\[
\exists M  \geq 0, \; \exists \delta > 0 \; st,\; 
|g(x)| \leq M \; for \; |x-a|<\delta\] 
\end{proof}
\end{theorem}

\begin{remark} We have:\\
\begin{enumerate}[(i)]
\item $f:\RR^{n} \rightarrow \RR^{m}$ is continuous iff: $f^{i}:\RR^{n} \rightarrow \RR$ is continuous for $i=1,\dots , m$
\item Polynomial functions in n-variables, $f(x^{1}, \dots ,x^{n})$, are continuous
\item Rational functions, $R(x)= \frac{P(x)}{Q(x)}$, are continuous where defined, ie: $Q(x) \neq 0$ and P, Q are polynomials in n-variables.
\end{enumerate}
\end{remark}

\begin{theorem}\label{T:Lin trans cont}
Linear transformations are continuous.
\begin{proof}
$T:\RR^{n} \rightarrow \RR^{m}$ let $a \in \RR^{n}$ to show: $\lim_{x\to a}T(a+h) = T(a)$, where $h = (h^1 , \dots , h^n )$
\begin{align*}
|T(a+h) - T(a)| & = |T(h)|=|T(h^{1}e_{1}+ \dots +h^{n}e_{n})| =|h^{1}T(e_{1}) + \dots +h^{n}T(e_{n})|\\ 
&\leq  |h^{1}||T(e_{1})|+ \dots |h^{n}||T(e_{n})| \leq |h|(T(e_{1})+ \dots T(e_{n})) \\
So: \quad |T(a+h) - T(a)| &\leq  M|h| \quad where \quad M= \sum_{i=1}^{n}|T(e_i)| \\
So \: given \quad \epsilon > 0,\quad choose \quad \delta &= \frac{\epsilon}{M} \quad such \: that \quad |h|< \delta \Rightarrow |T(a+h) - T(a)|< \epsilon \\
\end{align*}
\end{proof}
\end{theorem}

\begin{example}
$f(x,y)= \frac{x^{2} - y^{2}}{x^{2} +y^{2}}, \quad (x,y)=(0,0)$ assume $\quad \lim_{(x,y) \to (0,0)} f(x,y) = L$

\[\forall \epsilon > 0, \quad  \exists \delta >0  \quad such\: that \quad 0<|(x,y)|<\delta \Rightarrow |f(x,y)-L|<\epsilon \]
\text{Plug $(x,0)$ into $f$:} 
\[f(x,0) \;= \frac{x^{2}-0}{x^{2}-0} = 1\]
\text{Plug $(0,y)$ into $f$:} 
\[ f(0,y)\;= \frac{0-y^{2}}{0 +y^{2}} = -1\]
\begin{align*}
If \: |x|< \delta \quad |f(x,0)| < \delta & \Rightarrow |f(x,0) - L|< \epsilon \quad ie \quad |1-L|< \epsilon\\
If \: |y|< \delta \quad |f(0,y)| < \delta& \Rightarrow |f(0,y) - L|< \epsilon \quad ie \quad |-1-L|< \epsilon\\
&\Rightarrow \epsilon = \frac{1}{2} \quad contradiction! \\
\shortintertext{Now consider $ y=mx, m \in \RR$}
&f(x,mx)=\frac{x^{2} - (mx)^{2}}{x^{2} + (mx)^{2}} = \frac{1-m^{2}}{1+m^{2}}\\
&\lim_{x \to 0}(\lim_{y \to 0} f(x,y)) = \lim_{x \to 0}1 = 1\\
&\lim_{y \to 0}(\lim_{x \to 0} f(x,y)) = \lim_{y \to 0}-1 = -1\\
\end{align*}
\text{However checking along straight lines is  not enough to prove continuity.}\\

\end{example}

\begin{example}

\[
 f(x,y) =
  \begin{cases}
   \frac{xy}{\sqrt{x^{2} + y^{2}}} & \text{if } (x,y) \neq (0,0) \\
   0       & \text{if } (x,y) = (0,0)
  \end{cases}
\]
Show f is continuous at (0,0)
\[\forall \epsilon > 0, \quad \exists \delta>0\]
\[\left| \frac{xy}{\sqrt{x^{2} + y^{2}}}\right| \leq \frac{|x| \cdot |y|}{\sqrt{x^{2} + y^{2}}} \leq \frac{\sqrt{x^{2} + y^{2}} \cdot \sqrt{x^{2} + y^{2}}}{\sqrt{x^{2} + y^{2}}}= \sqrt{x^{2} + y^{2}} = |(x,y)|\]
Since: \[\begin{diagram}
\node[3]{.} \arrow{s,r,-}{y} \arrow{wsw,t,-}{ \sqrt{x^{2} + y^{2}}} \\
\node{.} \arrow[2]{e,b,-}{x} \node[2]{.}
\end{diagram}\]
\end{example}
\begin{note}
if the total degree of the neumerator is higher than the denominator in a rational function. Then the limit should be 0.
\end{note}

\begin{theorem}\label{T:composition}
If $f$ is continuous at a and $g$ is continuous at $f(a)$ then $g \circ f$ is continuous at a.
\end{theorem}

\subsection{Partial Derivitives}

\begin{definition}
Let $f:\RR^{n} \rightarrow \RR, \: a\in \RR$
\[Define: \quad D_{i}f(a) = \lim_{h \to 0}\frac{f(a^{1}, \dots , a^{i-1}, a^{i}+h, a^{i+1}, \dots , a^{n})}{h}\]
\end{definition}

\begin{example}
if $f:\RR^{n} \rightarrow \RR$
\[\left.\frac{df}{dx}\right| _{(a,b)} = D_{1}f(a,b)\]
\[\left.\frac{df}{dy}\right| _{(a,b)} = D_{2}f(a,b)\]
\[and \: in \: \RR^{3} \: we\: use \: \frac{df}{dx}, \frac{df}{dy} \: and \: \frac{df}{dz} \: etc.\]
\end{example}

\begin{example}
\begin{align*}
 f(x,y) &=
  \begin{cases}
   \frac{x^{2} - y^{2}}{x^{2} + y^{2}} & \text{if } (x,y) \neq (0,0) \\
   1       & \text{if } (x,y) = (0,0)
  \end{cases}\\
 D_{1}f(0,0) =\left.\frac{df}{dx}\right| _{(0,0)} &=  \lim_{x \to 0}\frac{f(x,0) - f(0,0)}{x}= \lim_{x \to 0}\frac{\frac{x^{2}-0}{x^{2}-0} -1}{x} = 0\\
D_{2}f(0,0) =\left.\frac{df}{dy}\right| _{(0,0)} &=  \lim_{y \to 0}\frac{f(0,y) - f(0,0)}{y}= \lim_{y \to 0}\frac{\frac{0-y^{2}}{0+y^{2}} -1}{y} = \frac{-2}{y}= \pm \infty\\
\end{align*}
\end{example}

\subsection{Total Derivitive}


In 1 dimention we write the following for the derivitive of $f:\RR \rightarrow \RR$
\[\quad f^{'}(a)=\lim_{h \to 0}\frac{f(a+h) - f(a)}{h}\]
we try to write it in higher dimentions $f:\RR^{n} \rightarrow \RR^{m}$ in this form
\begin{align*}
\lim_{h \to 0}\left[\frac{f(a+h) - f(a)}{h} - f^{'}(a)\right] &=\lim_{h \to 0}\left[\frac{f(a+h) - f(a) - h \cdot f^{'}(a)}{h}\right]\\
&=\lim_{h \to 0}\frac{|f(a+h) - f(a) - h \cdot f^{'}(a)|}{|h|} =0 \\
\end{align*}
For $f:\RR^{n} \rightarrow \RR^{m}$ consider the tangent line at a: $y=f(a) +f^{'}(a)(x-a)$\\
call $x-a = h$ then we have: $y=f(a) +f^{'}(a)(h)$\\
this is an Affine transformation, not a linear map.\\
Look at the map:
\[\lambda:h \rightarrow hf^{'}(a), \quad h \in \RR\]
This is a linear map.
\begin{align*}
\lambda(h_{1} + h_{2})&=(h_{1} + h_{2})f^{'}(a)= h_{1}f^{'}(a) + h_{2}f^{'}(a) =\lambda(h_{1}) + \lambda(h_{2})\\
\lambda(\alpha \cdot h)&=(\alpha h)f^{'}(a)=\alpha(hf^{'}(a))=\alpha \cdot\lambda( h)\\
&\lim_{h \to 0}\frac{|f(a+h) - f(a) - \lambda(h)|}{|h|} =0 \\
\end{align*}

\begin{definition}[Total Derivitive]\label{D:Total Derivitive}
$f:\RR^{n} \rightarrow \RR^{m}\: or \:(f:A \rightarrow \RR^{m}, \: A \subset \RR^{n}, \:A\;is\;open)$
is differentiable at a $(a \in A)$ if we can rind a linear transformation $ \lambda:\RR^{n} \rightarrow \RR^{m}$ st:
\[\lim_{h \to 0}\frac{|f(a+h) - f(a) - \lambda(h)|}{|h|} =0 \]
The linear transformation $\lambda$ is called the total derivitive of f at a and denoted Df(a) st
\[Df(a)=\lambda(h)\] 
\end{definition}

\begin{example} 
$f:\RR^{n} \rightarrow \RR^{m}, \: f(x)=k, \: k \in\RR^{m} $ is differentiable at $a\in\RR^{n}$ with the 0 linear transformation $0:f:\RR^{n} \rightarrow \RR^{m}, \: 0(h)=0$
\[\lim_{h \to 0}\frac{|f(a+h) - f(a) - 0(h)|}{|h|} = \lim_{h \to 0}\frac{|k - k - 0|}{|h|}= 0 \]
\end{example}

\begin{example}
If $f:\RR^{n} \rightarrow \RR^{m}$ is a linear transformaton, it is differentiable at $a\in\RR^{n}$ with linear transformation $Df(a) = f$
\[\lim_{h \to 0}\frac{|f(a+h) - f(a) - f(h)|}{|h|}= \lim_{h \to 0}\frac{|f(a+h -a -h)|}{|h|} = 0\]
\end{example}

\begin{theorem}[Uniqueness of Total Derivitive]\label{T:Uniqueness of Total Derivitive}
If f is differentiable at a then there exists a unique linear transformation, $ \lambda:\RR^{n} \rightarrow \RR^{m}$, such that
\[\lim_{h \to 0}\frac{|f(a+h) - f(a) - \lambda(h)|}{|h|} =0 \]
\begin{proof}
suppose $ \mu:\RR^{n} \rightarrow \RR^{m}$ is another linear transformation such that:
\[\lim_{h \to 0}\frac{|f(a+h) - f(a) - \mu(h)|}{|h|} =0 \]
deduce that $\lambda= \mu \:\forall h\in\RR^{n} \; ie\; \lambda(h)= \mu(h)$
\begin{align*}
\frac{|\lambda(h)- \mu(h)|}{|h|}&= \frac{|\lambda(h) +f(a) -f(a+h) +f(a+h) -f(a)- \mu(h)|}{|h|}\\
&\leq \frac{|f(a+h) -f(a) -\lambda(h)|}{|h|} +  \frac{|f(a+h) -f(a) -\mu(h)|}{|h|}\\
\shortintertext{Conclude that:} \qquad \qquad \qquad &\\
\:lim_{h \to 0}\frac{|\lambda(h)- \mu(h)|}{|h|} &\leq 0 + 0 =0 \quad (*)
\end{align*}
Let h=0 $\lambda= 0=\mu$ since $\lambda, \mu$ are linear. Now fix $h \in \RR^{n}$, $h\neq0$ and let $t\in\RR$ such that $th\in\RR^{n} $ then replace $h$ with $th$ in (*):
\begin{align*}
\lim_{t \to 0}\frac{|\lambda(th)- \mu(th)|}{|th|}&= \lim_{t \to 0}\frac{|t\lambda(h)- t\mu(h)|}{|t||h|}\\
&= \lim_{t \to 0}\frac{|t|}{|t|}\frac{|\lambda(h)- \mu(h)|}{|h|}= \frac{|\lambda(h)- \mu(h)|}{|h|} = 0\\
\lambda(h)&=\mu(h)\\
\end{align*}
\end{proof}
\end{theorem}

\begin{definition}[Jacobian Matrix]\label{D:Jacobian Matrix}
$f:\RR^{n} \rightarrow \RR^{m}$ is differentiable at $a \in \RR^{n}$ and it is derivitive at a $Df(a):\RR^{n} \rightarrow \RR^{m}$ is a linear map. Then the matrix representation of $Df(a)$ is $f^{'}(a) \in \MM_{mxn}$ and is called the Jacobian Matrix of f at a.
\end{definition}

\begin{example}\label{Df example}
$f:\RR^{2} \rightarrow \RR^{2}, \quad f(x,y)=(x^{2},x+5) \quad x,y \in \RR$\\
Show that $Df(1,2)(h^{1}, h^{2})=(4h^{1} +  h^{2}, h^{1})$:
\begin{align*}
&f((1,2) +(h^{1}, h^{2})) - f(1,2) -Df(1,2)(h^{1}, h^{2})\\
&= f(1+h^{1}, 2+ h^{2}) - f(1,2) - (4h^{1}+ h^{2}, h^{1})\\
&=((1+h^{1})^{2}(2+ h^{2}), (1+h^{1} +5)) - (2,6)  - (4h^{1}+ h^{2}, h^{1})\\
&=(2+ h^{2} + 2(h^{1})^{2} +(h^{1})^{2}h^{2} + 2h^{1}h^{2} + 4h^{1} -2 -4h^{1} -h^{2}, 6+h^{1} - 6 -h^{1})
\end{align*}
\textrm{Take length:}
\[|(2(h^{1})^{2} +(h^{1})^{2}h^{2} + 2h^{1}h^{2}, 0)| \leq 2|h|^{2} +|h|^{2}|h| + 2|h||h| = 4|h|^{2} + |h|^{3}\]
\textrm{So:}
\begin{align*}
&\lim_{h \to 0}\frac{|f((1,2) +(h^{1}, h^{2})) - f(1,2) -Df(1,2)(h^{1}, h^{2})|}{|h|}\\
& \leq
\lim_{h \to 0}\frac{4|h|^{2} + |h|^{3}}{|h|} =  \lim_{h \to 0}4|h| + |h|^{2}=0
\end{align*}
\end{example}

\begin{definition}
$f^{'}(a)$ is the matrix representation of $Df(a)$
\[Df(a)(h)^{t}= \left(\! \begin{array}{c} y^{1} \\ y^{2}\\ \vdots\\ y^{m} \end{array}\! \right) = f^{'}(a) \left(\! \begin{array}{c} h^{1} \\ h^{2}\\ \vdots\\ h^{n} \end{array}\! \right) \]
\[ f^{'}(a) = \begin{pmatrix}
  D_{1}f^{1}(a) & D_{2}f^{1}(a) & \cdots &D_{n}f^{1}(a) \\
  D_{1}f^{2}(a) & D_{2}f^{2}(a) & \cdots & D_{n}f^{2}(a) \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  D_{1}f^{m}(a) & D_{2}f^{m}(a) & \cdots & D_{n}f^{m}(a)
 \end{pmatrix}\]
\end{definition}

\begin{example} With this new information we can tackle example \ref{Df example}:\\
$f:\RR^{2} \rightarrow \RR^{2}, \quad f(x,y)=(x^{2},x+5) \quad x,y \in \RR$\\
Show that $Df(1,2)(h^{1}, h^{2})=(4h^{1} +  h^{2}, h^{1})$:
\[\frac{df^{1}}{dx} = 2xy, \quad \frac{df^{1}}{dy} = x^{2}, \quad \frac{df^{2}}{dx} = 1, \quad \frac{df^{2}}{dy} = 0\]
\[f^{'}(1,2)=\begin{pmatrix}
 4&1 \\
  1&0 \\
 \end{pmatrix}\]
\[f^{'}(1,2) \left(\!\! \begin{array}{c} h^{1} \\  h^{2} \end{array}\!\! \right)= \begin{pmatrix}
 4&1 \\
  1&0 \\
 \end{pmatrix}\!\!\! \left(\!\! \begin{array}{c} h^{1} \\  h^{2} \end{array}\!\! \right)=  \left(\!\!\! \begin{array}{c} 4h^{1} + h^{2}\\  h^{2} \end{array}\!\! \right)\]
\end{example}

\begin{remark}
Having  directional derivitives in all directions $u\neq 0$ is not enough to guarantee $df(a)$ exists.
\end{remark}

\begin{theorem}
If $f$ is differentiable at a then $f$ is continuous at a.
\begin{proof}
\begin{align*}
\lim_{h \to 0}|f(a+h)-f(a)| &= \lim_{h \to 0}|f(a+h)-f(a) -Df(a) + Df(a)|\\
&\leq \lim_{h \to 0}\frac{|f(a+h)-f(a) -Df(a)(h)|}{|h|}\cdot|h| + \lim_{h \to 0}| Df(a)(h)|\\ 
&= 0 
\end{align*}
since $Df(a)$ is a linear transformation $Df(a)$ is continuous so: \[\lim_{h \to 0}| Df(a)(h)| = | Df(a)(0)| = 0\].
\end{proof}
\end{theorem}

\subsection{The Chain Rule}
\begin{theorem}[Chain Rule]\label{T:Chain Rule}
if $f:\RR^{n} \rightarrow \RR^{m}$ is differentiable at a and $f:\RR^{m} \rightarrow \RR^{k}$ is differentiable at $f(a)$ then $g \circ f:\RR^{n} \rightarrow \RR^{k}$ is differentiable at a and 
\[D(g \circ f)(a) = Dg(f(a))\circ Df(a)\]

\[\begin{diagram}
\node{\RR^{n}} \arrow{e,t}{Df(a)}  \arrow{se,b}{D(g\circ f)(a)}
\node{\RR^m}  \arrow{s,r}{Dg(f(a))} \\
 \node[2]{\RR^{k}}
\end{diagram}\]
\[(g\circ f)^{'}(a)= g^{'}(f(a))\cdot f^{'}(a), \quad \textrm{where $\cdot$ represents matrix multiplication}\]

\begin{proof}
if $b=f(a)$ and we let $Df(a) = \lambda$ and $Dg(f(a))=\mu$ then if we define:
\begin{align}
\varphi(x) &=f(x)-f(a) -\lambda(x-a)\\
\psi(y) &= g(y) - g(b) - \mu(y-b)\\
\rho(x) &= g\circ f(x) - g\circ f(a) - \mu \circ \lambda (x -a)
\end{align}
\text{Then:}
\begin{align}
\lim_{h \to 0}\frac{|f(a+h)-f(a) -Df(a)(h)|}{|h|} &= \lim_{x \to a}\frac{|\varphi(x)|}{|x-a|} = 0\\
\lim_{h \to 0}\frac{|g(b+h)-g(b) -Dg(b)(h)|}{|h|} &= \lim_{y \to b}\frac{|\psi(y)|}{|y-b|} = 0
\end{align}
We must show:
\[\lim_{h \to 0}\frac{|g\circ f(x) - g\circ f(a) - \mu \circ \lambda (x -a)|}{|h|} = \lim_{x \to b}\frac{|\rho(x)|}{|x-b|} = 0\]
Now:
\begin{align*}
\rho(x) &=g(f(x)) - g(b) - \mu(\lambda(x-a)) \\
&= g(f(x)) - g(b) - \mu(f(x) - f(a) - \varphi(x)) \qquad \; \textmd{by (1)}\\
&= [g(f(x)) - g(b) - \mu(\lambda(f(x)-f(a)))] \\
&= \mu(\varphi(x)) = \psi(f(x)) + \mu(f(x)) \qquad \qquad \qquad \quad \textmd{by (2)}
\end{align*}
Thus we must Prove
\begin{align}
&\lim_{x \to a}\frac{|\psi(f(x))|}{|x-a|} = 0\\
&\lim_{x \to a}\frac{|\mu\varphi(x)|}{|x-a|} = 0
\end{align}
It follows from (5) that for some $\delta > 0 $  we have
\[|\psi(f(x))|<\epsilon|f(x) - b| \quad if\; |f(x) - b|<\delta\]
which is true if $|x-a|< \delta_{1} $ for a suitable $\delta_{1}$. We also have that if T is a linear transformation then $\exists M \geq 0\; such \; that\;  |T(x)|<M|x|$. So then:
\begin{align*}
|\psi(f(x))| &<\epsilon|f(x) - b| \\
&= \epsilon|\varphi(x) + \lambda(x-a)|\\
& \leq \epsilon|\varphi(x)| + \epsilon M|x-a|
\end{align*}
So
\[\lim_{x \to a}\frac{|\psi(f(x))|}{|x-a|} \leq \lim_{x \to a}\frac{\epsilon|\varphi(x)|}{|x-a|}  + \lim_{x \to a}\frac{\epsilon M|x-a|}{|x-a|} = \epsilon M \rightarrow 0\]
Also
\[\lim_{x \to a}\frac{|\mu\varphi(x)|}{|x-a|} \leq \lim_{x \to a}\frac{M|\varphi(x)|}{|x-a|} = 0\]
\end{proof}
\end{theorem}

\begin{theorem}\label{s}
Define $s:\RR^2 \rightarrow \RR \quad s(x,y)=x + y$ then $s$ is differentiable  and $Ds = s$
\begin{proof}
S is linear so
\begin{align*}
s((x,y) + (x^{'},y^{'})) &=s(x+x^{'},y+y^{'})= s(x,y) + s(x^{'},y^{'})\\
s(\lambda(x,y)) &= \lambda s(x,y)\\
\lim_{h \to 0}\frac{|s(a+h) - s(a) -s(h)|}{|h|} = 0
\end{align*}
\end{proof}
\end{theorem}

\begin{theorem}\label{p}
Define $p:\RR^2 \rightarrow \RR, \quad p(x,y)=xy$, then $p$ is differentiable  and:\\
$Dp(a,b):\RR^2 \rightarrow \RR$ is linear with $Dp(a,b)(h,k) = ak + bh$ and $p^{'} = (b,a)$
\begin{proof}
use of derivitive
\begin{align*}
p((a,b)+(h,k)) - p(a,b) - Dp(a,b)(h,k) &= p(a+h,b+k) - p(a,b) - (ak + bh)\\
&=(a+h)(b+k) - ab - (ak + bh) = hk\\
\frac{|p((a,b)+(h,k)) - p(a,b) - Dp(a,b)(h,k)|}{|(h,k)|} &= \frac{|hk|}{\sqrt{h^2 + k^2}} \leq  \frac{\sqrt{h^2 + k^2}\sqrt{h^2 + k^2}}{\sqrt{h^2 + k^2}} = \sqrt{h^2 + k^2} \rightarrow 0
\end{align*}
\end{proof}
\end{theorem}

\begin{remark}
To check some $T:\RR^n \rightarrow \RR^m$ is linear we listed two properties:
\begin{align*}
T(x+y) &= T(x) +T(y)\\
T(\lambda x) &= \lambda T(x)\\
\shortintertext{we can instead just check:}
T( \lambda x + y) &= \lambda T(x) + T(y)
\end{align*}
\end{remark}

\begin{corollary}
$f,g:\RR^{n} \rightarrow \RR$ differentiable at $a \in \RR^{n}$
\begin{enumerate}[(i)]
\item $D(f+g)(a) = Df(a) + Dg(a)$
\item Product rule: $D(f \cdot g)(a) = g(a)\cdot Df(a) + f(a) \cdot Dg(a)$
\item Quotient rule: if $g(a) \neq 0, \; D(\frac{f}{g})(a) = \frac{1}{g(a)^2}\cdot (g(a)\cdot Df(a) - f(a) \cdot Dg(a))$
\end{enumerate}
\end{corollary}
\begin{proof}
For (i):\\
We can consder the function $s$ from theorem~\ref{s}, $s:\RR^2 \rightarrow \RR \quad s(x,y)=x + y$, but acting on $f$ and $g$ ie $s(f,g) = f+g$ and $Ds =s $
\[D(f+g)(a)= Ds(f(a),g(a)) \circ D(f,g)(a) = s \circ(Df(a),Dg(a)) = Df(a) + Dg(a)\]
For (ii):\\
We can consder the function $p$ from theorem~\ref{p}, $p:\RR^2 \rightarrow \RR \quad p(x,y)=xy$, but acting on $f$ and $g$ ie $p(f,g) = fg$ with  $Dp(f,g)(h,k) = fk + gh$
\[D(f \cdot g)(a) = Dp(f,g)\cdot D(f,g)(a)= Dp(f(a),g(a)) \cdot (Df(a),Dg(a)) = f(a)\cdot Dg(a) + g(a)\cdot Df(a)\]
(iii) follows from (ii)
\end{proof}

\subsection{Mixed Derivitives}

$f:\RR^n \rightarrow \RR  , a \in \RR$
\[D_{i} = lim_{h \rightarrow 0}\frac{f(a^1 , \dots ,a^{i-1},a^{i} + h , a^{i+1}, \dots , a^n ) - f(a)}{h}\]
if $D_{i}f(x)$ exists for al a in some open set $U$ then we get a function $ U \xrightarrow {D_{i}} \RR , \; x \rightarrow D_{i}f(x)$ then we can talk about partial derivitives of $D_{i}f$ eg $D_{j}(D_{i}f(x)) = D_{ij}f(x)$\\
If $D_{i}f(x)$ exists $ \forall x \in U$ this is a function of $x$ and we can consider  $D_{j}(D_{i}f(x)) = D_{ji}f(x)$\\
In general $i \neq j$ eg $f(x,y)=x^{3}y^{5}:$
\begin{alignat*}{2}
D_{1}f(x,y) &= 3x^{2}y^{5} &\qquad  D_{2}f(x,y) &= 5x^{3}y^{4}\\
D_{2,1}f(x,y) &= 15x^{2}y^{4} &D_{1,2}f(x,y) &= 15x^{2}y^{4}
\end{alignat*}

\begin{theorem}
If $D_{i,j}$ and $D_{j,i}$ are continuous on an open set containing $a$ then
 \[D_{i,j} = D_{j,i}\]
\begin{proof} from homework 5:\\ 
First we repeat the well-known proof that, if $g : U \rightarrow \RR$ is continuous and $g(p) > 0$,
then there exists a neighborhood $V$ of $ p (p \in V \subset U,\; V \; open)$ with
\[q \in V \Rightarrow g(q) > 0\]
Take $\epsilon = g(p)$ in the defnition of continuity of $g$. There there exists a $V$ open with
$p \in V$ and
\[q \in V \Rightarrow |g(q) - g(p)| < g(p)\]
Since 
\[g(p) - g(q) \leq |g(q) - g(p)| < g(p) \Rightarrow  -g(q) < 0 \Leftrightarrow g(q) > 0\]
we get the result. The set V can be taken to contain a closed rectangle $[a, b] \! \times\! [c, d]$.

We apply the result to $g = D_{1,2}f - D_{2,1}f$. Assume (by contradiction) that $g(p)$ is not
always 0. Then there exists a point $p$ with $g(p) \neq 0$. We can assume that $g(p) > 0$,
otherwise consider $-g$. The function $g$ is given to be continuous. We have (using
Fubini twice)
\[0<\int_{[a, b] \! \times\! [c, d]}(D_{1,2}f(x,y) - D_{2,1}f(x,y))dA\]
\[=\int_{a}^{b}\left(\int_{c}^{d}D_{1,2}f(x,y)dy\right)dx - \int_{a}^{b}\left(\int_{c}^{d}D_{2,1}f(x,y)dx\right)dy\]
\[= \int_{a}^{b}\left(D_{1}f(x,d) - D_{1}f(x,c)\right)dx - \int_{c}^{d}\left(D_{2}f(b,y) - D_{2}f(a,y)\right)dy\]
\[= (f(b, d)-  f(a, d) - f(b, c) + f(a, c)) - (f(b, d)-  f(b, c) - f(a, d) + f(a, c)) = 0\]
using the fundamental theorem of calculus 6 times. This is a contradiction, so the
mixed partial derivatives are equal on the rectangle.
\end{proof}
\end{theorem}

\begin{theorem}\label{maxmin}
$A \subset \RR$ If the max or min of $f:A \rightarrow \RR$ occur at a point $a$ in the interior of $A$ and $D_{i}f(x)$ exists then $Df(a) = 0$
\begin{proof}
Consider $h(x) = f(a^{1}, \dots , a^{i-1} , x^{i}, a^{i+1}, \dots a^{n})$ $x$ in an open interval arround $a^{i}$.\\ Since $f$ has a max or min at $a$, $h$ has a max or min at $a^{i}$
\[\frac{dh}{dx}(a^{i}) = D_{i}f(a)\]
By analysis 2:
\[\frac{dh}{dx}(a^{i}) =0 \Rightarrow Df(a) = 0\]
\end{proof}
\end{theorem}

\begin{note}
The converse of Theorem \ref{maxmin} is not true, even in one dimension.
\end{note}



\subsection{Jacobian}
For $f:\RR^{n} \rightarrow \RR^{m}$ with total derivitive $Df(a):\RR^{n} \rightarrow \RR^{m}$ a linear map. Then  the Jacobian $f^{'}(a) \in \MM_{mxn}$ is the  unique representation of $Df(a)$ in the standard basis.

\begin{theorem}\label{jacob}
If  $f:\RR^{n} \rightarrow \RR^{m}$ is differentiable at a then $D_{i}f^{j}(a)$ exists $\forall i = 1, \dots , n\; \forall j = 1, \dots , m$ and the jacobian matrix is \[f^{'}(a) = (D_{i}f^{j}(a))_{j = 1, \dots , n}^{j=1,\dots , m}\]
\[ f^{'}(a) = \begin{pmatrix}
  D_{1}f^{1}(a) & D_{2}f^{1}(a) & \cdots &D_{n}f^{1}(a) \\
  D_{1}f^{2}(a) & D_{2}f^{2}(a) & \cdots & D_{n}f^{2}(a) \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  D_{1}f^{m}(a) & D_{2}f^{m}(a) & \cdots & D_{n}f^{m}(a)
 \end{pmatrix}\]
Where $f(x)= (f^{1}(x) , \dots , f^{m}(x)), \; f^{i}:\RR^{n} \rightarrow \RR$
\begin{proof}
Case $m=1$
\[
\begin{diagram}
\node{\RR} \arrow{e,t}{h}  \arrow{se,b}{f \circ h}
\node{\RR^n}  \arrow{s,r}{f} \\
 \node[2]{\RR}
\end{diagram}\]
\[ h(t) = (a^1 , \dots , a^{i-1}, t , a^{i+1}, \dots , a^{n}) \qquad \left.\frac{d(f \circ h)}{dt}\right| _{t=a^{i}} = D_{i}f(a)\]
\[\lim_{t \rightarrow a^{i}}\frac{(f\circ h)(t) - (f\circ h)(a^i)}{t-a^i} = \lim_{t \rightarrow a^{i}}\frac{f(a^1 , \dots , a^{i-1}, t, a^{i+1}, \dots , a^n) - f(a^1 , \dots , a^n)}{t-a^i} \]
$h$ is differentiable because its components are differentiable ie component $h^i$ is either constant $a^j$ where $j \neq i$ or $t$ when $j = i$
\begin{align*}
Dh(t)&=(Dh^{1}(t), \dots , Dh^{n}(t))\\
&=(0, \dots , 1, \dots , 0)
\end{align*}
\[ h^{'}(a^i) = \begin{pmatrix}
  0 \\
 0\\
  \vdots  \\
 1\\
\vdots  \\
0
 \end{pmatrix}_{(m \times 1)}\]

Case $m>1 $\\
$f:\RR^n \rightarrow \RR^m $
\[f(x) = (f^{1} (x), \dots f^{m}(x))\]
\[Df(a) = (Df^{1} (a), \dots Df^{a})\]
\[ f^{'}(a) = \begin{pmatrix}
  (f^1)^{'}(a) \\
  \vdots\\
(f^m)^{'}(a)\\
 \end{pmatrix}_{(m \times n)}\]
\[ f^{'}(a) = \begin{pmatrix}
  D_{1}f^{1}(a) & D_{2}f^{1}(a) & \cdots &D_{n}f^{1}(a) \\
  D_{1}f^{2}(a) & D_{2}f^{2}(a) & \cdots & D_{n}f^{2}(a) \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  D_{1}f^{m}(a) & D_{2}f^{m}(a) & \cdots & D_{n}f^{m}(a)
 \end{pmatrix}\]
\end{proof}
\end{theorem}

\begin{remark}
Abuse of notation since if $f:\RR \rightarrow \RR$
\[\text{this is a number} \rightarrow  \frac{dg(t_{0})}{dt}| = g'(t_{0}) \leftarrow \text{this is the $1 \times 1$ jacobian matrix}\]
\end{remark}

\begin{example}
\[ G(x,y) =
  \begin{cases}
   \frac{x^{2}y}{x^{4} + y^{2}} & \text{if } (x,y) \neq (0,0) \\
   0       & \text{if } (x,y) = (0,0)
  \end{cases}\]

Fix a vector $u \in \RR^2$ , $u=(u^1 , u^2 ) \neq (0,0), \quad u^2 \neq 0$ then the directional derivitive $D_{u}$ with $h \in \RR$ is:

\begin{align*}
D_{u}G(0,0) &= \lim_{h \rightarrow 0}\frac{G((0,0) + hu) - G(0,0)}{h} =  \lim_{h \rightarrow 0}\frac{G(hu^1 , hu^2 ) - 0}{h}\\
&= \lim_{h \rightarrow 0}\frac{(hu^1)^2(hu^2)}{(hu^1)^4 + (hu^2)^2} \cdot \frac{1}{h} =   \lim_{h \rightarrow 0}\frac{h^3 (u^1)^2 u^2}{h(h^4(u^1)^4 + h^2(u^2)^2)}\\
&=  \lim_{h \rightarrow 0}\frac{ (u^1)^2 u^2}{h^2(u^1)^4 + (u^2)^2)} = \frac{(u^1)^2}{u^2}\\
\shortintertext{$u^2=0$}
D_{u}G(0,0) &=  \lim_{h \rightarrow 0}\frac{G(hu^1 , h \! \cdot \!0)}{h}=  \lim_{h \rightarrow 0}\frac{(\frac{(hu^1)^2 \! \cdot \! 0}{(hu^1)^4 + 0^2})}{h} = 0
\end{align*}




\end{example}

\begin{theorem}
 $f:\RR^n \rightarrow \RR^m $ if $D_{j}f^{i}(x)$ exist $ \forall x \in u, U\; open,  a \in U,  \forall i = 1,\dots, m,$ and $ j = 1, \dots, n$ and if $D_{j}f^{i}(x)$ continuous at $a$ ie 
\[\lim_{x \rightarrow a}(D_{j}f^{i}(x)) = D_{j}f^{i}(a)\]
then $Df(a)$ exists and $f$ is differentiable at $a$
\begin{proof}
As in the proof of theorem \ref{jacob} It suffices to consider the case $ m=1$, so that $f:\RR^n \rightarrow \RR$. Then
\begin{align*}
f(a+ h) - f(a) &= f(a^{1} + h^{1}, a^{2}, \dots , a^{n}) &&- f(a^{1}, \dots , a^{n})\\
&+ f(a^1 + h^1 , a^2 + h^2, a^3 , \dots , a^n ) &&-  f(a^{1} + h^1 , a^2 ,  \dots , a^{n})\\
&+ \dots  &&- \dots\\
&+ f(a^1 + h^1 ,\dots ,  a^n + h^n ) &&-  f(a^{1} + h^1 ,  \dots, a^{n-1} + h^{n-1} , a^{n})
\end{align*}
Recal from theorem \ref{jacob} that $D_{1}f$ is the derivitive of the function $h$ defined by\\ $h(x) = (x, a^2 , \dots , a^n )$. Applying the mean-value theorem to $h$ we obtain
\[ f(a^{1} + h^{1}, a^{2}, \dots , a^{n}) - f(a^{1}, \dots , a^{n}) = h^{1} \cdot D_{1}f(b_{1}, a^{2} , \dots, a^{n}) \]
for some $b_{1}$ between $a^1 $ and $a^1 + h^1 $. Similarly the $ith$ term in the sum equals 
\[h^{i} \cdot D_{i}f(a^1 + h^1 ,\dots ,  a^{i-1} + h^{i-1},  b_{i}, a^{i+1}, \dots , a^n ) = h^{i}D_{i}f(c_{i}) \quad \text{for some $c_{i}$} \]
Then
\begin{align*}
\lim_{h \rightarrow 0}\frac{|f(a+h) - f(a) - \sum_{i=1}^{n}D_{i}f(a) \cdot h^{i}|}{|h|} &= \lim_{h \rightarrow 0}\frac{| \sum_{i=1}^{n}[D_{i}f(c_{i}) - D_{i}f(a) ]\cdot h^{i}|}{|h|}\\
 & \leq \lim_{h \rightarrow 0}| \sum_{i=1}^{n}[D_{i}f(c_{i}) - D_{i}f(a)]|\cdot \frac{| h^{i}|}{|h|}\\
 & \leq \lim_{h \rightarrow 0}| \sum_{i=1}^{n}[D_{i}f(c_{i}) - D_{i}f(a)]|\\
&=0
\end{align*}
Since $D_{i}f$ is continuous at $a$ and as $h \rightarrow 0, c^{i} \rightarrow  a^{i}$.
\end{proof}
\end{theorem}

\begin{definition} If $f:\RR^n \rightarrow \RR^m$ has partial derivitives $ D_{j}f^{i} \quad \forall x \in U , \; U \; open, \;  a \in U$ and $D_{j}f^{i}$ is continuous at $a$ then we say $f$ is continuously differentiable at $a$. 
\end{definition}

\begin{example}
$f:\RR^2 \rightarrow \RR$, with $x:\RR \rightarrow \RR, y:\RR \rightarrow \RR$. 
\[\text{Define} \quad g:\RR \rightarrow \RR \quad g(t) = f(x(t),y(t))\]
\begin{align*}
\frac{dg(t_0)}{dt} &= (g^{'}(t_0)) = f^{'}(x(t_0), y(t_0)) \cdot \left(
    \begin{array}{c}
      x^{'}(t_0) \\
     y^{'}(t_0)
    \end{array}
  \right)\\
&= \frac{df}{dx}(x(t_0),y(t_0)) + \frac{df}{dy}(x(t_0),y(t_0))\\
&= \frac{df}{dx}(x(t_0),y(t_0)) \cdot  \frac{dx}{dt}(t_0) + \frac{df}{dy}(x(t_0),y(t_0)) \cdot  \frac{dy}{dt}(t_0) \\
&= \frac{df}{dx}\cdot \frac{dx}{dt} + \frac{df}{dy}\cdot \frac{dy}{dt}
\end{align*}
\end{example}

\subsection{20/11/11 some deep graphs in romans notes, may have a crack producing them later on}

\subsection{Inverse Function Theorem}

\begin{lemma}
Let $A \subset \RR^n$ be a rectangle with interior $A^{0}$ and let $g : A \rightarrow\RR^n$ be continuously differentiable. If there exist a constant $M > 0$ such that 
\[ |D_{j}g^{i}(x)| \leq M, \quad x \in A^{0}, \quad i,j=1, \dots , n. \]
then
\[ |g(x) - g(y)| \leq n^{2}M|x-y|, \quad x,y \in A.\]
\begin{proof}
 Fix $ i = 1, \dots , n.$ Then
\begin{align*}
g^{i}(y) - g^{i}(x) &= g^{i}(y^1 , y^2 , \dots , y^n) - g^{i}(x^1 , x^ 2 , \dots , x^n )\\
&= g^{i}(y^1 , y^2 , \dots , y^n) - g^{i}(x^1 , y^2 , \dots , y^n)  +  g^{i}(x^1 , y^2 , \dots , y^n)  - g^{i}(x^1 , x^ 2 , \dots , y^n )\\ 
& \quad +  g^{i}(x^1 , x^ 2 , \dots , y^n ) - \dots +  g^{i}(x^1 , x^ 2 , \dots , y^n ) -  g^{i}(x^1 , x^ 2 , \dots , x^n )\\ &= \sum^{n}_{j=1}(g^{i}(x^1 , x^ 2 , \dots , x^{j-1} , y^{j}, \dots , y^n ) - g^{i}(x^1 , x^ 2 , \dots , x^{j-1} , x^{j}, y ^{j+1}, \dots , y^n ) \\
&= \sum^{n}_{j=1}(y^{j} \! -\! x^{j})D_{j}g^{i}(z^{i}_{j})
\end{align*}
where $z^{i}_{j}$ is between $y^j$ and $x^j$, and we used the mean-value theorem in the interval between
$y_j$ and $x_j$ and in the $j$ variable. Using the triangle inequality and $|z^j| \leq |z|, $ we get
\[ |g^{i}(y) - g^{i}(x)| \leq \sum^{n}_{j=1}|y^{i} - x^{i}|M \leq \sum^{n}_{j=1}|y - x|M = nM|y-x|.\]
Since $|z| \leq \sum_{i}|z^i |, $ finally we get
 \[ |g(x) - g(y)| \leq \sum^{n}_{i=1}|g^{i}(y) - g^{i}(x)| \leq  \sum^{n}_{i=1} nM|y-x| =  n^{2}M|y-x|. \]
\end{proof}
\end{lemma}
\begin{remark}
 It is clear that the dimension of the target space enters only in the last line of
the calculation. If $g : \RR^n \rightarrow \RR^m$, then we get as upper bound $nmM|x- y|$. The inequality
is actually not optimal: one can use the Cauchy-Schwarz inequality twice to get a bound
$n^{1/2}m^{1/2}M|x-y|$ for $g:\RR^n \rightarrow \RR^m$.
\end{remark}

\setcounter{equation}{0}

\begin{theorem}[Inverse Function Theorem]
Theorem Let $f : \RR^n \rightarrow \RR^n$ be continuously differentiable on an open set containing $a$ and assume $detf^{'}(a) \neq 0$. Then there exists an open set $V$ containing $a$ and an open set $W$ containing $f(a)$ such that $f : V \rightarrow W$ is bijective with $f^{-1}: W \rightarrow V$ continuously differentiable and which satisfies:
\[ (f^{-1})^{'}(y) = [f^{'}(f^{-1}(y))]^{-1}, \quad y \in W.\]

\begin{proof}
\textit{Step 1:}\\ We reduce proving the theorem to the case where actually $f^{'}(a) = I_{nn}$. Call $ \lambda = Df(a)$. This is a linear transformation with nonsingular matrix representation $f^{'}(a)$, as det$f^{'}(a) \neq 0$. Therefore, $\lambda$ is invertible. The inverse $\lambda^{-1}$ is also a linear transformation, so $D(\lambda^{-1})(y) = \lambda^{-1}$ for $y \in \RR^n$. Both $\lambda$ and its inverse are continuous as linear transformations. Consider the function $ h = \lambda^{-1} \circ f$ defined on an open set comtaining a. \\ Then:
\[Dh(a) = D \lambda^{-1} (f(a)) \circ Df(a) = \lambda ^{-1} \circ Df(a) = \lambda^{-1} \circ \lambda = Id, \]

by using the chain rule. Here $ Id$ is the identity transformation. This gives $ h^{'}(a) = I_{n \times n}$, which has determinant $1\neq0$. Let $A$ be the matrix representation of $ \lambda^{-1}$. (which gives that $A^{-1}$ is the matrix representation of $\lambda= D\lambda$). This is an $ n \times n$ matrix with constant entries, i.e. not depending on $y$. Moreover, h is continuously differentiable, as
\[ (D_{j}h^{i}(x)) = h^{'}(x) = [ \lambda^{-1} \circ Df(x)] = A \cdot f^{'}(x) = A(D_{j}f^{i}(x)), \]


with entries depending continuously on x. Therefore, $h$ satisfies the conditions of the
inverse function theorem. Suppose that we can prove the conclusion of it for $h$, i.e. that
there exists an open set $V$ containing $a$ and $\tilde{W}$ open containing $h(a) = \lambda^{-1}(f(a))$ such that
$h : V \rightarrow \tilde{W}$ is bijective with continuously differentiable inverse $h^{-1}$. Even more, assume
that we have prove the formula for the derivative of the inverse of $h$:
\[ (h^{-1})' (z) = [h'(h^{-1}(z))]^{-1}. \]

Define $W =\lambda(\tilde{W}) =(\lambda^{-1})^{-1}(\tilde{W})$. This is the inverse image of $\tilde{W}$ by $\lambda^{-1}$, which is continuous, so it is an open set. Since $\lambda$ is bijective, $f= \lambda \circ h$ is bijective on $V$ with image $\lambda(\tilde{W}) = W$. Moreover, 
\[f^{-1} = h^{-1} \circ \lambda^{-1}, \]
which is continuously differentiable as the composition of two such maps. By the chain
rule for Jacobian
\[(f^{-1})'(y) = (h^{-1})'(\lambda^{-1}(y)) \cdot (\lambda^{-1})'(y) =  [h'(h^{-1}(\lambda^{-1}(y)))]^{-1} A = [h'((\lambda \circ h)^{-1}(y))]^{-1}  A = [h'(f^{-1}(y))]^{-1}A \]
\[ = [A^{-1}h'(f^{-1}(y))]^{-1} = [\lambda'h'(f^{-1}(y))]^{-1} = [(\lambda \circ h)'(f^{-1}(y))]^{-1} = [f'(f^{-1}(y))]^{-1}. \]

All these imply that it is enough to work with $h = \lambda ^{-1} \circ f$. The main property we will
use is that $h'(a)=I_{n \times n}$. For simplicity in our notation we call this function f so we can
assume that
\[f'(a) = I_{n \times n}. \]
This also means that $\lambda = Df(a) = Id$.\\
\textit{Step 2:}
The function f cannot take the value $f(a)$ arbitrarily close to $a$. Suppose that there is a sequence $h_{n} \in \RR^n$ such that $ h_{n} \rightarrow 0$ and $f(a + h_{n}) = f(a)$. We plug the sequence into the definition of the derivative at $a$ and use that $Df(a) = Id$ to get
\[ 0 = \lim_{h_{n} \rightarrow 0}\frac{|f(a + h_{n}) - f(a) - Df(a)(h_{n})|}{|h_{n}|} = \lim_{h_{n} \rightarrow 0}\frac{|-h_{n}|}{|h_{n}|} = 1\]
So this is a contradiction. Therefore, we can find a closed rectangle $U$ containing a such
that
\[f(x) \neq f(a), \quad \forall x \in U\backslash \{a\}. \]


\textit{Step 3:} The determinant is a polynomial expression in the entries of a matrix. If the matrix entries depend continuously on $x$, the same is true for the determinant of the matrix. So det$f'(x)$ is a continuous function on an open set containing $a$. Since det$f'(x) \neq 0$, by the inertia principle, there exists a small enough (rectangular) neighbourhood of $a$, which
we call $U$ again, such that
\begin{equation}
 \text{det}f'(x) \neq 0, \quad x \in U \end{equation} 
Moreover the partial derivatives $D_{j}f^{i}(x)$ are continuous and $D_{j}f^{i}(a) = \delta_{ij},$ as $Df(a) = Id$. So, for $x$ close enough to $a$ we have
\begin{equation}
|D_{j}f^{i}(x) - \delta_{ij}| < \frac{1}{2n^{2}}, \quad i,j = 1, \dots , n, \quad x \in U
\end{equation}
We assumed again that the neighbourhood is $U$\\
\textit{Step 4:}  Constructing a contraction map and showing that $f$ is injective in appropriate small meighbourhood. Now we define the function
\[ g(x) = f(x) - x\]
and apply the Lemma to this function for the closed rectangle $U$. We notice that $D_{j}g^{i}(x) =D_{j}f^{i}(x) - \delta_{ij}$, as we know the partial derivatives of the identity function $x$. We deduce that
\begin{equation}
|g(x_{1}) - g(x_{2})| \leq n^{2}\frac{1}{2n^2}|x_{1} - x_{2}| = \frac{1}{2}|x_{1} - x_{2}| \end{equation}

The choice of the neighbourhood in (2) so that the constant $1/(2n^{2})$ appears on the right is motivated with the desire to get g as a contraction map (with constant $1/2$) as we see in (3). Now the triangle inequality in the form $|a|-|b|\leq  |a-  b|$ gives
\[|x_{1} - x_{2}| - |f(x_{1}) - f(x_{2})| \leq |(x_{1} - x_{2}) - (f(x_{1}) - f(x_{2}))| = |-g(x_{1}) + g(x_2)| < \frac{1}{2}|x_{1} - x_{2}| \]
\begin{equation}
\Rightarrow |x_{1} - x_{2}| - \frac{1}{2}|x_{1} - x_{2}| < |f(x_{1}) - f(x_{2})| \Rightarrow  \frac{1}{2}|x_{1} - x_{2}|  <|f(x_{1}) - f(x_{2})|
\end{equation}

Here $x_1, x_2$ are in $U$. We immediately see that on $U$ the function $f$ is injective:
\[f(x_1)=f(x_2) \Rightarrow |x_1 - x_2| =0 \Rightarrow x_1 = x_2.\]

We still have not determined the neighbourhoods $W$ of $f(a)$ and $V$ of $a$.\\
\textit{Step 5:}  Determination of the minimum distance of $f(a)$ to the image of the boundary of $U$ and definition of $W$.\\ We have assumed that on the closed rectangle $ U$ we have $f(x) \neq f(a)$ for $x \neq a$. This is definitely true on the boundary of $U$, denoted $\partial U$, which is a closed and bounded set, i.e. compact. The function $ m(x) = |f(x)-  f(a)|$ is continuous on a neighbourhood of $\partial U$ and nonzero on it. It achieves a minimum value on $\partial U$ (an advanced argument from Real Analysis is that the image of a compact set is compact, so that $m(\partial U)$ is compact, which
means closed and bounded. Such a set has a maximum and minimum). The minimum value cannot be zero, say
\[ \min_{x \in \partial U} m(x) = \min_{x \in \partial U} |f(x) - f(a)| > 0 .\]
Now define 
\[W = \{y \in \RR^n , |y-f(a)| < \delta / 2\}.\]
\textit{Step 6:}  Comparison of $|y - f(x)|$ with $|y-  f(a)|$ for $x \in \partial U$, and $y \in W$. We have 
\[ |f(x)- f(a)| \geq \delta, \quad |y - f(a)| \leq \delta /2 \Rightarrow -|y-f(x)| + \delta \leq -|y-f(x)|+|f(x) - f(a)| \leq |y-f(a)| < \delta /2 \]
\[ \Rightarrow \delta /2 = \delta - \delta /2 < |y-f(x)| \Rightarrow |y-f(a)|< \delta / 2 < |y-f(x)|. \]
\textit{Step 7:} Show that for $y_0 \in W$ there exists a unique $x_0 \in U^{0}$ such that $f(x_0) = y_0$. The
uniqueness is obvious from the fact that $f$ is injective on $U$. The construction of such an $x_0$ is tricky. We define another function on $U$ by
\[g(x) = |f(x)-y_0 |^2 = \sum^{n}_{i=1}(f^{i}(x) - y^{i}_{0})^2.\]

This function in continuously differentiable, as it is a sum of the squares of the components.
On the compact set $U$ the function $g$ achieves its minimum, say at $x_0$, i.e. $g(x_0) \leq g(x)$ for
$x \in U$. We claim that $x_0$ is the desired point with $f(x_0) = y_0$. First we see that $x_0$ is in the
interior of the set $U$. On the boundary of $U$ the function $g(x)$ has values $> \delta /2$, by Step 6,
while $g(a) < \delta /2$. So the minimum is not achieved on the boundary of U. Therefore, it is
achieved in an interior point. This point has to be a critical point of $g$, i.e. $D_j g(x_0) = 0,
\; j = 1, \dots , n$. We calculate them to be
\[ 2 \sum^{n}_{i=1}(f^i (x_0) - y^{i}_{0})D_{j}f^{i}(x_0) = 0, \quad j=1, \dots , n.\]

This is a homogeneous system of linear equations with unknowns $f^{i}(x_0) - y^{i}_{0}$ and coefficients $D_j f^{i}(x_0)$. The determinant of the coefficients of the system is nonzero, as $x_0 \in U$. The system has a unique solution, and this solution is the zero vector, i.e
\[ 0 = f^{i}(x_0) - y^{i}_{0}, \quad i=1, \dots, n \Rightarrow f(x_0) = y_{0}. \]

\textit{Step 8:} We define $V$ and Show that $f:V \rightarrow W$ is bijective and continuous. We define $V = U^0 \cap f^{-1} (W)$. Clearly $f : V \rightarrow W$ is bijective. Moreover, $V$ is open as the intersection of the open set $U^0$
and the open set $f^{-1} (W)$, which is open as the inverse image of an open set W by the continuous function $f$. We now rewrite (4) as
\begin{equation}
|x_1 - x_2 | < 2| f(x_1) - f(x_2)| \Leftrightarrow |f^{-1}(y_1)- f^{-1}(y_2)| < 2|y_1 - y_2 |
\end{equation}
with $y_1 = f(x_1)$ and $y_2 = f(x_2),\; y_i \in W$. This shows that $f^{-1}$ is a Lipschitz function with constant 2, so that it is continuous. Alternatively, choose $\delta = \epsilon /2$ in the definition of continuity.\\

\textit{Step 9:}  Show that $f^{-1}$ is differentiable. Let $\mu = Df(x_1)$. Since $f^{-1} \circ f = Id$, the chain
rule gives the only possible choice for $Df^{-1}(y_1)= \mu^{-1}$. Here $f(x_1) = y_1$ and later $f(x) = y$.
By the definition of the derivative we have
\[ f(x) - f(x_1) = \mu (x-x_1) + \phi(x-x_1), \quad \lim_{x \rightarrow x_1}\frac{|\phi(x - x_1)|}{|x - x_1|} = 0.\]

We apply to the equation the linear transformation $\mu^{-1}$ to get
\[ \mu^{-1}(y-y_1) = x - x_1 + \mu^{-1}(\phi(x - x_1)) \Rightarrow x - x_1 -\mu^{-1}(y-y_1) = \mu^{-1}(\phi(x - x_1)) \]
\[ \Rightarrow f^{-1}(y) - f^{-1}(y_1) - \mu^{-1}(y - y_1) = -\mu^{-1}(\phi(x-x_1)). \]

By the definition of the derivative of $f^{-1}$ at $y_1$ we need to show that
\begin{equation}
\lim_{y \rightarrow Y_1}\frac{|-\mu^{-1}(\phi(x-x_1))|}{|y-y_1|}=0
\end{equation}
Since $\mu^{-1}$ is a linear transformation, we have seen that it is a bounded linear operator, i.e.
there exists a constant $\tilde{M}$ with
\[|\mu^{-1}(y)| \leq \tilde{M}|y|, \quad \forall y \in \RR^n . \]
Since
\[ \frac{|-\mu^{-1}(\phi(x-x_1))|}{|y-y_1|} \leq \frac{\tilde{M}|\phi(x-x_1)|}{|y-y_1|} \]
by the sandwich theorem it is enough to prove that
\[\lim_{y \rightarrow Y_1}\frac{|\phi(x-x_1)|}{|y-y_1|} =0\]
We have 
\[\frac{|\phi(x-x_1)|}{|y-y_1|} = \frac{|\phi(x-x_1)|}{|x-x_1|}\frac{|x-x_1|}{|y-y_1|} \leq \frac{|\phi(x-x_1)|}{|x-x_1|}\cdot 2,\]
by (5). Moreover, $y \rightarrow y_1$ iff $ x \rightarrow x_1$ as $ f$ is continuous at $x_1$ and $f^{-1}$ is continuous at $y_1$.We know that
\[\lim_{x \rightarrow x_1} \frac{|(\phi(x-x_1))|}{|x-x_1|} = 0 \]
This suffices to prove (6)\\
\textit{Step 10:} The partial derivatives $D_j (f^{-1})^i(y)$ are continuous. We know that the Jacobian of $f^{-1}(y)$ is
\[(f^{-1})'(y) = (D_j (f^{-1})^i(y)) = [f'(f^{-1}(y))]^{-1} = (D_j f^i (x))^{-1}. \] 
The inverse of the matrix $(D_jf^i(x))$ can be calculated as a quotient of two $n \times n$ determinants with entries among $D_jf^i(x)$. The denominator is the determinant of the Jacobian at $x$, which is nonzero for $x \in U$. The whole expression depends continuously on $x \in V$. As $f^{-1}$ is continuous, the inverse matrix depends continuously on $y \in W$. The individual entries are the partial derivatives of $f^{-1}$.
\end{proof}

\end{theorem}

\subsection{Implicit Function Theorem}
\dgARROWLENGTH=1em
\begin{example}
\[x^2 + y^2 = 1, \quad y = g(x)\] 
\[ 2x + 2y\frac{dy}{dx} = 0, \quad \frac{dy}{dx} = \frac{dg}{dx} = \frac{-x}{y}, \quad y \neq 0 \]
\end{example}
\begin{example}
\[y^2 + xz + z^2 - e^z - 4 = 0 \quad \text{(impossible to solve for z)}\]
\[set \; F(x,y,z) = y^2 + xz + z^2 - e^z - 4, \quad F(x,y, g(x,y)) = 0\]
\[
\begin{diagram}
\node[2]{F}\arrow{sw,-}\arrow{se,-}\arrow{s,-}\\
\node{X} \arrow{s,-} 
\node{Y} \arrow{s,-}
\node{Z}  \arrow{wsw,-}\arrow{sw,-} \\
\node{X} \arrow{e,-} \node{Y}
\end{diagram}
\]
Differentiate in $x$:
\begin{align*}
\frac{d}{dx}F(x,y,g(x,y)) &= \frac{dF}{dx}\frac{dx}{dx} + \frac{dF}{dy}\frac{dy}{dx} + \frac{dF}{dz}\frac{dz}{dx}\\
&=  \frac{dF}{dx} + \frac{dF}{dz}\frac{dg}{dx}  = 0\\
\frac{dg}{dx} &= -\frac{\frac{dF}{dx}}{\frac{dF}{dz}} = - \frac{z}{x^2 +2z - e^z }\\
\frac{dF}{dy}=0 \overset{chain}{\underset{rule}{\Rightarrow}} \frac{dF}{dy} + \frac{dF}{dz}\frac{dg}{dy} \Rightarrow 
\frac{dg}{dy} &= -\frac{\frac{dF}{dy}}{\frac{dF}{dz}} = - \frac{2y}{x^2 +2z - e^z }\\
\end{align*}
the point $(0,e,2)$ satisfies $F(x,y,z)=0$
\[e^2 + 0\cdot 2 + 2^2 - e^2 -4 =0\]
\begin{align*}
\left.\frac{dg}{dx}\right|_{(0,e)} &=- \frac{z}{x^2 +2z - e^z } = - \frac{2}{0+2\cdot 2- e^2 }\\
\left.\frac{dg}{dy}\right|_{(0,e)} &=- \frac{2y}{x^2 +2z - e^z }  = - \frac{2e}{0+2\cdot 2- e^2 }
\end{align*}
valid for $\frac{dF}{dz} \neq 0$
\end{example}

\textbf{General situation:} $m$ equations with $ m$ unknowns $y^1, \dots , y^m$
\begin{alignat*}{2}
f^1 &(x^1 , \dots , x^n , y^1 , \dots , y^m) = 0 &\qquad & \text{depends on n parameters:}\; x^1 , \dots , x^n\\
f^2 &(x^1 , \dots , x^n , y^1 , \dots , y^m)= 0 &\qquad & \text{Try to solve for:} \;  y^1 , \dots , y^m\\
&\vdots \qquad \qquad \vdots \qquad \qquad \vdots   		&\quad & \\
f^m &(x^1 , \dots , x^n , y^1 , \dots , y^m)= 0 &\quad &\\
\end{alignat*}
\[ x=(x^1 , \dots , x^n) , \qquad y=(y^1 , \dots , y^m)\]
So we have:
\begin{align*}
f^1(x,y) &=0\\
f^2(x,y) &=0\\
\vdots\\
f^m(x,y) &=0\\
\end{align*}
Define $f(x,y) = (f^1(x,y), \dots , f^m (x,y))=\underbracket[0.5pt]{0}_{vector} =\underbrace{(0,\dots,0)}_{
          \mathclap{m}}$\\
Let $a \in \RR^n , \; b \in \RR^m$ such that $f(a,b,) = 0$ when we can find for each $(x^1,  \dots, x^n) $  near $a=(a^1 , \dots , a^n )$ a unique $y=(y^1 , \dots , y^m )$ near $b= (b^1 , \dots , b^m)$ such that: $f(x,y)=0$, \\$f(x^1 , \dots , x^n , y^1 , \dots , y^m) = 0$

\begin{theorem}[Implicit Function Theorem]\label{implicitFunction}
$f:\RR^n \times \RR^m \rightarrow \RR^m$ continuously differentiable on an open set containing $(a,b), \; a \in \RR^n , \; b \in \RR^m.$ moreover $f(a,b)=0$\\
consider the matrix \[M=(D_{j+n}f^{i}(a,b))^{i=1,\dots,m}_{j=1,\dot,m}\] assume det$M \neq 0$. Then there exist two open sets $A \subset \RR^n, \; b \subset \RR^m, \; a \in A, \; b \in B$. such that $\forall x \in A, \exists$ unique $g(x) \in B$ such that $f(x,g(x))=0$ Moreover $g:A \rightarrow B$ is differentiable.
\begin{proof} 
Increase the dimension of the target. Define $F:\underbrace{U}_{in \;  \RR^n \times \RR^m} \rightarrow \RR^n \times \RR^m$
\[F(x^1,\dots , x^n,y^1, \dots,y^m) = (x^1, \dots , x^n, f^1(x,y), \dots , f^m(x,y))\]
\[F(x,y) = (x,f(x,y))\]
F is continuously differentiable because $x^1 , \dots , x^n$ are continuously differentiable and $f^1(x,y), \dots , f^m(x,y)$ are continuously differentiable (because $f(x,y)$ is continuously differentiable)
\[F(a,b) = (a,f(a,b)) = (a,0)\]
\[
 F'(a,b) =
 \left( \begin{array}{cccc|ccc}
 1 & 0 & \cdots & 0 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 & 0 & \cdots & 0 \\
  \vdots  & \vdots  & \ddots & \vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 1 & 0 & \cdots & 0 \\
\hline
  \frac{df^1}{dx^1} & \frac{df^1}{dx^2}& \cdots\frac{df^1}{dx^n} & \frac{df^1}{dy^1} & \cdots & \frac{df^1}{dy^m}\\
\vdots  & \vdots  & \ddots & \vdots & \vdots & & \vdots \\
  \frac{df^m}{dx^1} & \frac{df^m}{dx^2}& \cdots\frac{df^m}{dx^n} & \frac{df^m}{dy^1} & \cdots & \frac{df^m}{dy^m}
 \end{array} \right)
\]
\[ F'(a,b) =
 \left( \begin{array}{c|c}
 I_{n \times n} & 0_{n \times m}\\
\hline
\text{\scriptsize * Some $m \times n$} & M_{m \times m}\\
\text{\scriptsize matrix} & 
 \end{array} \right) \]

det$M \neq 0$ (reducing from top left entry).\\
By the inverse funct theorem, $\exists$ an open set $W$ containing $F(a,b) = (a,0)$ and an open set containing $(a,0)$ which I can take to be a rectangle $A \times B, \;  a \in A , \; b \in B, \; A$ open in $\RR^n, \; B$ open in $\RR^m$.\\
\[F:A \times B \rightarrow W \text{ is bijective}\]
\[\exists h = F^{-1}:W \rightarrow A \times B \; \text{such that} \; F \cdot h = id\]
$h$ is continuously differentiable.
\begin{equation*} 
  \addtolength{\fboxsep}{5pt} 
   \boxed{ 
   \begin{gathered} 
      F(x^1,\dots , x^n,y^1, \dots,y^m) = (x^1, \dots , x^n, f^1(x,y), \dots , f^m(x,y))  \\ 
      F(x,y) = (x,f(x,y)) 
      \\ F \;\text{is continuously differentiable because} \; x^1 , \dots x^n \; \text{are continuously differentiable}
   \end{gathered} 
   } 
\end{equation*}
$h$ must have the form: $h(x,y) =  (x,k(x,y))$ for some function $k:W \rightarrow B, \; B \subset \RR^m$, $k$ continuously differentiable.
\[F(h(x,y) = (x,f(x,k(x,y))) = (x,y)\]
\[f(x,k(x,y)) = y\]
Set $y=0$
\[f(x,k(x,0))=0\]
The solution is $g(x)=k(x,0)$ (solution to $f(x,y)= 0$).
\end{proof}
\end{theorem}

\begin{theorem}\label{imp2}
Let $g : \RR^n \rightarrow \RR^p$ be a continuously differentiable function in an open set containing $a$ and assume that $p \leq n$. If $g(a) = 0$ and the rank of the $p \times n$ matrix
\[(D_jg^i(a))_{i=1,\dots,p \; j=1,\dots, n} \]
be equal to $p$. Then there exists an open set $A \subset \RR^n$ and a differentiable function $h : A \rightarrow \RR^n$ which is bijective onto an open set $V$ and $h^{-1}$ is differentiable and
\[(g \circ h)(x^1, x^2, \dots,x^n) = (x^{n-p+1}, x^{n - p+2}, \dots,x^n) \]
\begin{proof}
We can consider the function $g$ as $g : \RR^{n-p} \times \RR^P \rightarrow \RR^p$. The 'easy' case is as follows:\\
If the $p\times n$ matrix above is such that the last $p$ columns give a matrix $M$ with $det(M) \neq
0$, then we are exactly in the situation of the Implicit Function Theorem as worked out
above. The notation has only slightly changed: $x^{n-p+1} = y^1,\; x^{n-p+2} = y^2, \dots,x^n = y^p, \;
p = m,\; g = f$. We have found $h$ with $h(x, y) = (x, k(x, y))$ and 
\[(f \circ h)(x, y) = f(h(x, y)) = f(x, k(x, y)) = y,\]
and in our notation
\[(g \circ h)(x^1, x^2, \dots,  x^n) = (x^{n-p+1}, x^{n-p+2}, \dots, x^n).\]
In general we cannot assume that the last columns of the matrix give nonzero determinant. We know from Linear Algebra that there will be some $p$ columns with this property. Let these columns be $j^1, j^2, \dots, j^p$ with
\[M =(D_{j_k}g^i(a))_{i=1,\dots,p \; k=1,\dots ,p}, \qquad det(M) \neq 0.\]
We rearrange the variables as follows: Let $m : \RR^n \rightarrow \RR^n$ be defined by (put the variables
with superscript $j_k,\; k = 1, 2,\dots, p$ in the last entries and order in whatever way you want
the other variables)
\[m(x^1, x^2, \dots ,x^n) = (\dots, x^{j_1} ; x^{j_2},\dots, x^{j_p}).\]
Then $g \circ m$ is a function of the type discussed theorem \ref{implicitFunction}, so we can find a function $s : A \rightarrow \RR^n$
which is bijective onto an open set $V$ and $s^{-1}$ is differentiable and
\[ ((g \circ m) \circ s)(x^1, x^2, \dots, x^n) = (x^{n-p+1}; x^{n-p+2} , \dots,  x^n).\]
Then use $h = m \circ s$.
\end{proof}
\end{theorem}

\begin{example}
\[f: \RR^2 \rightarrow \RR^2, \quad f(x,y) = (xy, x^2 + y^2) = (z,w)\]
\[
\begin{pmatrix}
 \frac{dx}{dz} & \frac{dx}{dw}\\
\frac{dy}{dz} & \frac{dy}{dw}
 \end{pmatrix} =   \begin{pmatrix}
 \frac{dz}{dx} & \frac{dz}{dy}\\
\frac{dw}{dx} & \frac{dw}{dy}
 \end{pmatrix}^{-1} \]

\begin{alignat*}{2}
&z=xy, &\quad &y= \frac{z}{w} \\
&w = x^2 + y^2 = x^2 + \frac{z^2}{x^2} &\quad & \\
&wx^2 = x^4 + z^2 &\quad & \\
& x^4 - wx^2 + z^2 &\quad & (*)
\end{alignat*}
\[x=g(z,w)\]
Use implicit differentiation on $(*)$ with respect to $z$:
\[4x^3\frac{dx}{dz} - w \cdot 2x\frac{dx}{dz} + 2z = 0\]
\[\frac{dx}{dz}(4x^3 - 2xw) = -2z\]
\[\frac{dx}{dz} = \frac{-2z}{4x^3 - 2xw}=  \frac{-z}{x(2x^2 - w)}=  \frac{-y}{2x^2 - w}\]
Valid for
\[2x^2 - w \neq 0 \]
\[2x^2 - (x^2 + y^2) \neq 0 \]
\[x^2 - y^2 \neq 0 \]
\[ \Leftrightarrow f'(x,y) \neq 0\]

\[\left.\begin{aligned}
       & f(x,y) = 0 & \; &f(a,b)= 0 \\
        & f(x,g(x)) = 0 & \; &\text{solve implicitly for $y$} \\
	& x \in \RR^n, \; y \in \RR^m & \; & g:\RR^n \rightarrow \RR^m\\
	&f:\RR^n \times \RR^m \rightarrow \RR^m &\; & 
       \end{aligned}
 \right\}
 \qquad \text{Set up of implicit function theorem }\]
\[i=1,\dots,m \quad f^{i}(x^1 , \dots , x^n , g^1(x^1, \dots, x^n), \dots, g^m(x^1, \dots, x^n)) =0\]
how to compute $D_{j}g^{i}?$
\[D_{j}g^{i}(\dots) = 0\]
\[D_{1}f^i\cancel{\frac{dx^1}{dx^j}} + \cancel{\dots} +  D_{j}f^i\underbracket{\frac{dx^j}{dx^j}}_{= 1} + \cancel{\dots} + D_{n}f^i\cancel{\frac{dx^n}{dx^j}}+D_{n+1}f^i\frac{dg^1}{dx^j} + \dots + D_{n+m}f^i\frac{dg^m}{dx^j}=0\]
\[\underbrace{D_{n+1}f^i\frac{dg^1}{dx^j} + \dots + D_{n+m}f^i\frac{dg^m}{dx^j}}_{m \; \text{unknowns}}= - D_{j}f^i\frac{dx^j}{dx^j} \]
Check det of coefficents is $\neq 0$ 
\[\left[\begin{array}{ccc}
D_{n+1}f^1 & \dots & D_{n+m}f^1\\
\vdots & & \vdots\\
D_{n+1}f^m & \dots & D_{n+m}f^m\\
\end{array} \right] = M\]
\end{example}

\section{Integration}
\subsection{Multiple integrals}

$f:A \rightarrow \RR$, $A$ is a rectangle in $\RR^n$ $A= [a_1,b_1]\times \dots \times[a_n , b_n]$\\
Recall a partition $\mathcal{P}$ of $[a,b]$ is a collection of of points: $t_{0}, \dots , t_k$ with $a=t_0 < t_1 < \dots <t_k = b$\\
A Partition of a rectangle $ [a_1 , b_1]\times\dots \times [a_k , b_k]$ is a collection $\mathcal{P} = (P_1 , \dots , P_n)$ where $P_i$ is a partition of $[a_i, b_i], \; i=1,\dots ,n$ Subrectangles $[s_{j-1},s_j]\times[t_{m-1},t_m]$ Let $f$ be bounded on the rectangle  $ [a_1 , b_1]\times\dots \times [a_k , b_k]$

\begin{definition}
 Let $f$ be bounded on the rectangle  $ [a_1 , b_1]\times\dots \times [a_k , b_k]$ and let $S$ be subrectangle of the partition $\mathcal{P}$  
\[m_S(f) = \inf_{x \in S}f(x), \qquad M_S (f) = \sup_{x \in S}f(x) \]
Lower Riemann sum:
\[\mathcal{L}(f,\mathcal{P}) = \sum_{S}m_S(f).v(S)\]
where $v(s)$ is the volume of the subrectangle
\[S=[s_{l-1}, s_l] \times [t_{j-1},t_j] \times \dots \times[r_{k-1},r_k]\]
\[v(S)= (s_{l-1}- s_l)\cdot(t_{j-1},t_j)\cdots (r_{k-1},r_k)\]
Upper Riemann sum:
\[\mathcal{U}(f,\mathcal{P})= \sum_{S}M_S(f).v(S)\]
\[ \mathcal{L}(f,\mathcal{P}) \leq \mathcal{U}(f,\mathcal{P})\]
Refinement: A refinement $\mathcal{P}'$ of the partition $\mathcal{P}$ is as follows. Given $S$ a subrectangle of $\mathcal{P}'$, I can find a subrectangle T of $\mathcal{P}$ such that $S \subset T$ and $T= \cup_{S \subset T} S$, $S$ for $\mathcal{P}'$
\end{definition}

\setcounter{equation}{0}

\begin{lemma}
if $\mathcal{P}'$ is a refinement of $\mathcal{P}$, then:
\begin{align}
\mathcal{L}(f,\mathcal{P}) &\leq \mathcal{L}(f,\mathcal{P}')\\
\mathcal{U}(f,\mathcal{P}) &\geq \mathcal{U}(f,\mathcal{P}') 
\end{align}

\begin{proof} of (1)\\
Let $S$ be a subrectangle of $\mathcal{P}'$ and $T$ a subrectangle of $\mathcal{P}$ such that $S\subset T$ 
\begin{align*}
m_S(f) & \geq M_T(f) \\
m_S(f)v(S) &\geq M_T(f)v(S) \qquad ( \text{sum over all} \; S \subset T, \; S \; for \; \mathcal{P}')\\
\sum_{S \subset T}m_S(f)v(S) &\geq \sum_{S \subset T}m_T(f)v(S) = m_T(f)v(T)\\
\mathcal{L}(f,\mathcal{P}') = \sum_{T}\sum_{S \subset T}m_S(f)v(S) &\geq \sum_{T} m_T(f)v(T) = \mathcal{L}(f,\mathcal{P})\\
\end{align*}
\end{proof}
\end{lemma}

\begin{lemma}
For any two partitions $\mathcal{P}$ and $\mathcal{P}'$ we have:
 \[\mathcal{L}(f,\mathcal{P}) \leq \mathcal{U}(f,\mathcal{P}')\]
\begin{proof}
Take $\mathcal{P}''$ a refinement of $\mathcal{P}$ and $\mathcal{P}'$:
\[\mathcal{L}(f,\mathcal{P}) \leq\mathcal{L}(f,\mathcal{P}'') \leq \mathcal{U}(f,\mathcal{P}'') \leq  \mathcal{U}(f,\mathcal{P}')\]
\end{proof}
\end{lemma}

\begin{definition}
The lower Riemann integral \[\int\limits_{A \;-}f = \sup_{\mathcal{P}} \;\mathcal{L}(f, \mathcal{P}) , \quad (\mathcal{P}\; \text{partition of rectangle $A$})\]
The upper Riemann integral \[\int\limits_{A}^{-}f = \inf_{\mathcal{P}} \;\mathcal{U}(f, \mathcal{P})\]
$f$ is called integrable if 
\[ \int\limits_{A\;-}f = \int\limits_{A}^{-}f \quad and \quad \int\limits_{A} f = \int\limits_{A \;-}f = \int\limits_{A}^{-}f\] 
\end{definition}

\begin{theorem}[Riemann's Integrability Criterion]\label{reimann}
$f$ is integrable over the rectangle $A \Leftrightarrow \forall  \epsilon > 0, \; \exists$ a partition $\mathcal{P}$ of $A$ such that 
\[\mathcal{U}(f, \mathcal{P}) - \mathcal{L}(f, \mathcal{P}) < \epsilon \]
\begin{proof}
($ \Rightarrow $)\\
\begin{align*}
&\inf_{\mathcal{P}}(\mathcal{U}(f, \mathcal{P}) - \mathcal{L}(f, \mathcal{P}) = 0\\
\Leftrightarrow &\inf_{\mathcal{P}}\;\mathcal{U}(f, \mathcal{P}) - \sup_{\mathcal{P}}\; \mathcal{L}(f, \mathcal{P}) = 0\\
\Leftrightarrow  &\int\limits_{A \;-}f = \int\limits_{A}^{-}f\\
\end{align*}
($\Leftarrow$)\\
Assume $\int\limits_{A \;-}f = \int\limits_{A}^{-}f$, fix $\epsilon > 0$
\[\text{Since} \; \int\limits_{A \;-}\! f = \sup_{\mathcal{P}} \;\mathcal{L}(f, \mathcal{P}), \quad \text{so} \quad \exists \mathcal{P}' \; s.t \; \int\limits_{A \;-}f - \frac{\epsilon}{2} < \mathcal{L}(f, \mathcal{P}')\]
\[\text{Since} \; \int\limits_{A}^{-}f = \inf_{\mathcal{P}} \;\mathcal{U}(f, \mathcal{P}), \quad \text{so} \quad \exists \mathcal{P}' \; s.t \; \int\limits_{A}^{-}f + \frac{\epsilon}{2} > \mathcal{U}(f, \mathcal{P}')\]
Take $\mathcal{P}''$ a common refinement of $\mathcal{P}$ and $\mathcal{P}'$
\[\int\limits_{A}^{-}f + \frac{\epsilon}{2} \;>\; \mathcal{U}(f, \mathcal{P}'') \geq \mathcal{L}(f, \mathcal{P}'') \;> \int\limits_{A \;-}f - \frac{\epsilon}{2}\]
So
\[\mathcal{U}(f, \mathcal{P}'') - \mathcal{L}(f, \mathcal{P}'') < \left(\cancel{\int\limits_{A}^{-}\!f} + \frac{\epsilon}{2}\right) - \left(\cancel{\int\limits_{A \;-}\!\!f} - \frac{\epsilon}{2}\right) = \epsilon\]
\end{proof}
\end{theorem}

\begin{example} Non-Riemann integrable function $f:\RR^2 \rightarrow \RR^2$
\[f(x,y) =
  \begin{cases}
  1 & \text{if } x \in \QQ \\
   0      & \text{if } x \notin \QQ
  \end{cases} \]
\begin{alignat*}{2}
m_S(f) &= 0 &\qquad M_S(f)&=1\\
\mathcal{L}(f, \mathcal{P}) &= 0 &\qquad \mathcal{U}(f, \mathcal{P}) &=1
\end{alignat*}
\end{example}

If $C \subset \RR^n$, define the characteristic function of $C$ to be 
\[X_{C}(x) =\begin{cases}
  1 & \text{if } x \in C \\
   0      & \text{if } x \notin C
  \end{cases} \]
\setcounter{equation}{0}
If $f$ is bounded on $\bar{C}$ and $C$ is contained in a rectangle $A$, we define 
\[\int\limits_{C}f = \int\limits_{A}fX_{C}\]
$f:[a,b]\times[c,d] \rightarrow \RR$\\
Fix $x$ and consider $g_{x}:[c,d]\rightarrow\RR$ 
\[g_{x}(y) = f(x,y)\]
\[I(x)=\int_{c}^{d}g_{x}dy = \int_c^df(x,y)dy\]
\begin{equation}
\int_a^bI(x)dx = \int_a^b\left(\int_c^df(x,y)dy\right)dx
\end{equation}
Fix $y$ and define $h_{y}:[a,b]\rightarrow\RR$
\[h_y(x)=f(x,y)\]
\[J(y)=\int_{a}^{b}h_{y}dx = \int_a^bf(x,y)dx\]
\begin{equation}
\int_c^dJ(y)dy = \int_c^d\left(\int_a^bf(x,y)dx\right)dy
\end{equation}
$(1) = (2)$

\subsection{Fubini's theorem}

\begin{theorem}
Let $A$ be a rectangle in $\RR^n$ and let $B$ be a rectangle in $\RR^m$. $f:A \times B \rightarrow \RR$ is intergrable. define: 
\[ g_x: B \rightarrow \RR \quad  \text{ by } \quad g_x = f(x,y) , \qquad  \forall y \in B,\;  \forall x \in A \]
and let: 
\[ \left.\begin{aligned}
       \mathfrak{L}(x) &=  \int\limits_{B \;-}g_x =\int\limits_{B \;-}f(x,y)dy\\
       \mathfrak{U}(x) &=  \int\limits_{B}^{-}g_x =\int\limits_{B}^{-}f(x,y)dy
       \end{aligned}
 \; \right\}
 \qquad \text{exists} \; \; \forall x \in A\]
Then $\mathfrak{L}(x)$ and $\mathfrak{U}$ are intergrable over $A$, and:
\[\int\limits_{A}\mathfrak{L}(x)dx =\int\limits_{A} \left(\;\int\limits_{B \;-}f(x,y)dy \right)\! dx=\int\limits_{A} \left(\int\limits_{B}^{-}f(x,y)dy \right)\! dx = \int\limits_{A}\mathfrak{U}(x)dx = \int\limits_{A \times B}f\]
\begin{proof}
Let $\mathcal{P}_A$ be a partition of $A$, $\mathcal{P}_B$ be a partition of $B$. Let $S_A$ a subrectangle of $A$,  $S_B$ a subrectangle of $B$. Then the rectangles $S_A \times S_B$ give a partition $\mathcal{P}$ of $A\times B.$ \\
We will prove:
\[\mathcal{L}(f,\mathcal{P}) \underset{(1)}{\leq} \mathcal{L}(\mathfrak{L},\mathcal{P}_A) \underset{(2)}{\leq} \mathcal{U}(\mathfrak{L},\mathcal{P}_A) \underset{(3)}{\leq} \mathcal{U}(\mathfrak{U},\mathcal{P}_A) \underset{(4)}{\leq} \mathcal{U}(f,\mathcal{P})\]
Since $f$ is integrable over $A \times B$, given $\epsilon > 0$ Riemann's integrability criterion given a partition $\mathcal{P}$ of $A \times B$, such that: $\mathcal{U}(f,\mathcal{P}) - \mathcal{L}(f,\mathcal{P}) < \epsilon $. Then $\mathcal{P}$ defines $\mathcal{P}_A ,\; \mathcal{P}_B$ partitions of $A, \; B$ respectively. By the inequality above: $\mathcal{U}(\mathfrak{L},\mathcal{P}_A) - \mathcal{L}(\mathfrak{L},\mathcal{P}_A) < \epsilon $. By reimann's integrability criterion, $\mathcal{L}$ is integrable over $A$, since: 
\[\sup_{\mathcal{P}}\mathcal{L}(f,\mathcal{P})= \inf_{\mathcal{P}}\mathcal{U}(f,\mathcal{P}) = \int\limits_{A\times B}\! \! f \Rightarrow \int\limits_{A}\mathfrak{L}(x)dx = \sup_{\mathcal{P}_A}\mathcal{L}(\mathfrak{L},\mathcal{P}_A)= \inf_{\mathcal{P}_A}\,\mathcal{U}(\mathfrak{L},\mathcal{P}_A) = \int\limits_{A\times B}\! \!f\]
Works simularly with $\mathfrak{U}(x)$.\\
Side remark:
\begin{align*}
\mathcal{L}(f, \mathcal{P}) &\leq \mathcal{L}(\mathfrak{L}, \mathcal{P}_A)\\
\sup_{\mathcal{P}}\mathcal{L}(f, \mathcal{P}) &\leq \sup_{\mathcal{P}_A}\mathcal{L}(\mathfrak{L}, \mathcal{P}_A)\\
\mathcal{U}(\mathfrak{L}, \mathcal{P}_A) &\leq \mathcal{U}(f, \mathcal{P})\\
\inf_{\mathcal{P}_A}\mathcal{U}(\mathfrak{L}, \mathcal{P}_A) &\leq \inf_{\mathcal{P}}\mathcal{L}(f, \mathcal{P})
\end{align*}

\begin{align*}
(2) \quad \mathcal{L}(\mathfrak{L},\mathcal{P}_A) &\leq \mathcal{U}(\mathfrak{L},\mathcal{P}_A) \\ &\text{always true for  a function $\mathfrak{L}$, partition $\mathcal{P}_A$} \\ \;& \; \\
(3) \quad \mathcal{U}(\mathfrak{L},\mathcal{P}_A) &\leq \mathcal{U}(\mathfrak{U},\mathcal{P}_A)\\
&\mathfrak{L}(x)  =\int\limits_{B \;-}f(x,y)dy, \; \mathfrak{U}(x)  =\int\limits_{B}^{-}f(x,y)dy \Rightarrow \mathfrak{L}(x) \leq \mathfrak{U}(x) \\
 &\Rightarrow \mathcal{U}(\mathfrak{L}(x), \mathcal{P}_A) \leq \mathcal{U}(\mathfrak{U}(x), \mathcal{P}_A) \\
\end{align*}
$(4)$ is proved simularly to $(1)$ so we only prove $(1)$. 

\[\mathcal{L}(f,\mathcal{P})= \sum_{S}m_{s}(f) v(S) = \sum_{S_A, \; S_B}\! m_{S_A \times S_B}(f)  v(S_A \times S_B) = \sum_{S_A}\left(\sum_{S_B} m_{S_A \times S_B}(f)  v(S_B) \right)\! v(S_A)\]
Now, if $x \in S_A$, then clearly $m_{S_A \times S_B}(f) \leq m_{S_B}(g_x).$ Consequently, for $x \in S_A$ we have
\[\sum_{S_B} m_{S_A \times S_B}(f) \cdot v(S_B) \leq \sum_{S_B}m_{S_B}(g_x)\cdot v(S_B) \leq \int\limits_{B \;-}g_x = \mathfrak{L}(x).\]
Therefore
\[\sum_{S_A}\left(\sum_{S_B} m_{S_A \times S_B}(f)  v(S_B) \right)\! v(S_A) \leq \mathcal{L}(\mathfrak{L}, \mathcal{P}_A).\]
When the function is reimenn integral
\end{proof}
\end{theorem}

\subsection{Change of variables}
\begin{theorem}
Let $A \in \RR^n$ be open, $g:A \rightarrow \RR^n$ be injective and continuously differentiable with $det \;g'(x) \neq 0, \; \forall x \in A$. Let $f:g(A) \rightarrow \RR$ be integrable.Then we have change of variables formula:
\[\int\limits_{g(A)}\!f=\int\limits_{A}(f \circ g)\cdot |det \:g'(x)|dx\]
\end{theorem}

\section{Differential Forms}
\subsection{Manifolds}

\begin{definition}[$C^{\infty}$]
A function $f:\RR^n \rightarrow \RR^m$ is called a $C^{\infty}$ function if all partial derivitives of all orders of all components exists and are continuous
\end{definition}

\begin{definition}[Diffeomorphism]
Let $U, \; V$ be open sets in $\RR^n$. A $C^{\infty}$ function $h:U\rightarrow V$ bijective and $h^{-1}:V \rightarrow U$, also a $C^{\infty}$ function, is called a diffeomorphism from $U$ to $V$
\end{definition}

\begin{definition}
A set $M$ is a K-dim manifold in $\RR^n$ if the following condition (M) holds. For every $x \in M$:\\
(M): There exisits two open sets $U, \; V$ of $\RR^n, z\; x \in U$ and a diffeomorphsim $h:U \rightarrow V$ such that:
\[ h(U \cap M) = \{ y \in V \; s.t. \;y^{k+1} = y^{k+2} = \dots = y^{n} = 0\} \]
\end{definition}  

\begin{theorem}
 Let $A \rightarrow \RR^n$ be open and let $g : A \rightarrow \RR^p$ be a differentiable function such
that $g'(x)$ has rank $p$ on the set $g^{-1}(0)$. Then $g^{-1}(0)$ is an $n\! -\! p$ dimensional manifold in $\RR^n$.
\begin{proof}
 It follows directly from theorem \ref{imp2}. Let $x \in g^{-1}(0) = M$. We take $V = A$ in theorem\ref{imp2} so that we can find a diffeomorphism $H : V \rightarrow U$ , where $U$ is open in $\RR^n$ and 
\[g \circ H(x^1, x^2, \dots, x^n) = (x^{n-p+1}, x^{n-p+2}, \dots , x^n) \]
Let $h = H^{-1} : U \rightarrow V$ . We need to show that 
\[h(U \cap M) = \{y \in V,\; y^{n-p+1} = y^{n-p+2} = \dots = y^n = 0\}.\]
Let $y \in U \cap M$. Then $y \in g^{-1}(0)$, i.e. $g(y) = 0$. Since
\[h(g^{_1}(0)) = H^{-1}(g^{-1}(0)) = (g \circ H)^{-1}(0) = \{y \in V,\; y^{n-p+1} = y^{n-p+2} = \dots = y^n = 0\},\]
clearly we have for $ y \in g^{-1}(0)$ that $ h(y)$ has its last $p$ coordinates zero. The converse is
also obvious: if $z \in \{y \in V,\; y^{n-p+1} = y^{n-p+2} = \dots = y^n = 0\}$ then set $y = H(z) \in U$
and $g(y) = g(H(z)) = (z^{n-p+1},\dots, z^n) = (0,\dots ,0) \Rightarrow y \in g^{-1}(0) = M$ and $z = h(y) \in
h(U \cap M).$
\end{proof}
\end{theorem}

The following theorem gives the coordinate definition of a manifold M.

\begin{theorem}
A subset $M$ of $\RR^n$ is a $k$-dimensional manifold iff for every point $x \in M$ the following holds:\\
(C) There exists an open set $U \in \RR^n,\; x \in U$ and an open set $W \subset \RR^k$ and an injective
differentiable map $f : W \rightarrow \RR^n$ such that
\begin{enumerate}[(i)]
\item $f(W) = U \cap M$
\item rank $f'(y) = k \quad \forall y \in W$
\item $f^{-1} : f(W) \rightarrow W$ is continuous.
\end{enumerate}
\begin{proof}
 Lets assume that M is a manifold according to the deffnition (M). We choose the function $h : U \rightarrow V$ as in the definition. We define the set $W$ and the function $f$ as follows:
\[W = \{a \in \RR^k, \; (a, 0) \in h(U \cap M) \}, \quad f : W \rightarrow \RR^n, \quad  f(a) = h^{-1}(a, 0).\]
Here $(a, 0)$ is the vector with the last $n-k$ coordinates equal to $0$. Obviously $f(W) = U\cap M$, since
\[a \in W \Leftrightarrow (a, 0) \in h(U \cap M) \Leftrightarrow h^{-1}(a, 0) \in U \cap M \Leftrightarrow f(a) \in U \cap M.\]
We prove that $W$ is open. For $a \in W$, we have:
\[(a, 0) \in h(U \cap M) \Leftrightarrow h^{-1}(a, 0) \in U \cap M \Rightarrow h^{-1}(a, 0) \in U.\]
Since $h^{-1}$ is continuous, if $b$ is sufficiently close to $a$, so that $(a, 0)$ and $(b, 0)$ are sufficiently close, we can deduce that $h^{-1}(b, 0)$ is close enough to $h^{-1}(a, 0)$. Because $U$ open, if $h^{-1}(a, 0) \in U$, then also $h^{-1}(b, 0) \in U$. This gives $(b, 0) \in h(U)$. Because $h(U \cap M)$ consists exactly of the points with last $n- k$ components equal to $0, \; (b, 0) \in h(U\cap M) \Leftrightarrow b \in W$. We immediately see from the definition of $f$ and $W$ that $f^{-1}$ is continuous (it maps $h^{-1}(a, 0)$ to $a$ while $h$ is continuous).\\
We prove that the rank of $f'(y)$ is $k$ on $W$. For this we introduce another function
\[H : U \rightarrow \RR^k, \quad  H(z) = (h^1(z),\dots , h^k(z)),\]
i.e. $H$ has the same first $k$ coordinates as $h$ (and ignores the last $n - k$). We have
\[H(f(y)) = H(h^{-1}(y, 0)) = y, \quad  y \in W.\]
Therefore, $H'(f(y) )\cdot f'(y) = I_{k\times k}$ or, in terms of linear transformations:
\[DH(f(y)) \circ Df(y) = Id_{\RR^k}.\]
Because the composition is injective, $Df(y)$ is injective and the nullity plus rank theorem for $Df(y) : \RR^k \rightarrow \RR^n$ gives that the rank of $Df(y)$ is $k$.\\ \\
 \textit{The converse:} Suppose that $f : W \rightarrow \RR^n$ satisfies condition (C). We have $f'(y) \in M_{n\times k}$.
By rearranging the coordinates in $\RR^n$, we can assume that the rank of the first $k$ rows of $f'(a)$ is $k$. This means
\[det (D_jf^i(a))_{i,j=1,\dots ,k} \neq 0.\]
We define
\[g : W \times \RR^{n - k} \rightarrow \RR^n, \quad g(a, b) = f(a) + (0, b),\]
where $(0, b)$ has the first $k$ coordinates $0$. We have
\[g^i(a, b) = f^i(a), \quad i \leq k, \quad g^i(a, b) = f^i(a) + b^i, \quad i > k.\]
We compute its Jacobian matrix. For $i\leq k$
\begin{align*}
D_jg^i(a, b)  = D_jf^i(a) \Rightarrow D_jg^i(a, b) &= D_jf^i(a), \quad j \leq k,\\
and \quad D_jg^i(a, b) & = 0, \quad j > k.
\end{align*}
For $i > k$, however, we have
\[D_jg^i(a, b) = D_jf^i(a) + D_jb^i \Rightarrow D_jg^i(a, b) = \delta _{ij}, \quad j > k\]
while
\[D_jg^i(a, b)  = D_jf^i(a), \quad j \leq k.\]
The Jacobian matrix is therefore in block form
\[
 g'(a,b) =
 \left( \begin{array}{c|c}
 D_jf^i(a)_{i,j = 1,\dots , k}  & 0 \\
\hline
 D_jf^i(a)^{i=k+1 , \dots, n}_{j = 1,\dots , k}  & I_{(n-k)\times (n-k)} \\
 \end{array} \right)
\]
The calculation of the determinant in block form (which can be considered as successive expansion on the last column) gives that $det \;g'(a, b) \neq 0$. By the inverse function theorem, there exists an open set $V_1$ with $(a, 0) \in V_1$ and an open set $V_2$ containing $g(a, 0) = f(a)$, such that $g : V_1 \rightarrow V_2$ has a differentiable inverse $h : V_2 \rightarrow V_1$. Then, since $f(W) = U \cap M$, we have for $(x, 0) \in V_1,\; g(x, 0) \in M \Leftrightarrow f(x) \in M$: This gives
\[V_2 \cap M = \{g(x, 0), \; (x, 0) \in V_1\}.\]
\[h(V_2 \cap M) = g^{-1}(V_2 \cap M) = g^{-1}(\{g(x,  0), \; (x, 0) \in V_1\}) = V_1 \cap (\RR^k\times \{0\}).\]
\end{proof}
\end{theorem}
We also need the definition of manifold with boundary. While a $k$-dimensional manifold in $\RR^n$ looks like a $k$-dim  slice of $\RR^n$, according to condition (M), for a manifold with boundary in $\RR^n$, the part close to the boundary looks likes a half-slice of dimension $k$. To make this precise we define the half-space
\[\mathbb{H}^k = \{x \in \RR^k, \;  x^k \geq 0 \}.\]
Then
\[h(U \cap M) = \{ y \in V: \; y^k \geq 0, \;y^{k+1} = y^{k+2} = \dots = y^{n} = 0\}\]
is the substitute for condition (M). More precisely:

\begin{definition} 
A subset $M$ of $\RR^n$ is a $k$-dimensional manifold with boundary if for every point $x$ of $M$ either condition (M) holds or (exclusive) the following condition holds: \\
(M') There is an open set $U \rightarrow \RR^n$ containing $x$, an open set $V$ contained in $\RR^n$ and a
diffeomorphism $h : U \rightarrow V$ such that
\[h(U \cap M) = V \cap (\mathbb{H}^k\times \{0\}) = \{ y \in V: \; y^k \geq 0, \;y^{k+1} = y^{k+2} = \dots = y^{n} = 0\}.\]
Moreover, $h^k(x) = 0$.The set of points where condition (M') holds is called the boundary of $M$ and is denoted
by $\partial M$.
\end{definition}









\subsection{Linear Functionals}

\begin{definition}
Let $g^{i}:\RR^n \rightarrow \RR$ be a linear map, such a map is called a linear functional. The set of all linear functionals from $\RR^n \rightarrow \RR$ is called the dual space of $\RR^{n}$, denoted $(\RR^n)*$\\
let $g^{1}, \dots , g^{m}$ be linear functionals $g^{i}:\RR^n \rightarrow \RR$, then I can combine them to get a map $g:\RR^n \rightarrow \RR^{m}$ by $g(x) =(g^{1}(x), \dots , g^{m}(x)$)\\
$g:\RR^n \rightarrow \RR^{m}$ is linear such for $x,y \in \RR^n, \; \lambda \in \RR$
\begin{align*}
g(\lambda x +y) &= \lambda g(x) + g(y)
\shortintertext{this can be seen by}
g(\lambda x +y) &=(g^{1}( \lambda x + y), \dots , g^{m}( \lambda x + y) \\
&= ( \lambda g(x)^{1} +g^{1}(y), \dots ,\lambda g(x)^{m} +g^{m}(y))\\
&= \lambda (g^{1}(x), \dots, g^{m}(x)) + (g^{1}, \dots , g^{m})
\end{align*}
$[g^{i}]$ is the matrix representation of $g^{i}$\\
$[g^{i}] = (g_{1}^{i}, \dots , g_{n}^{i})$
\[ [g]_{mxn} = \begin{pmatrix}
  g_{1}^{1}  & \cdots & g_{n}^{1} \\
  \vdots   & & \vdots  \\
  g_{1}^{m} & \cdots &g_{n}^{m}
 \end{pmatrix}\]
\end{definition}

\begin{theorem}
$f:\RR^{n} \rightarrow \RR^{m}$ is differentiable at a iff $f^{i}$ are differentiable at a, $i=1, \dots , m$
and $Df(a) = (Df^{1}, \dots , Df^{m}(a))$
\begin{proof}
assume f is differentiable at $a$ we take the linear function $\Pi^{i}(x^{1}, \dots , x^{m}) = x^{i}$ and compose it with $f$ we get 
\[f^{i} =  \Pi^{i} \circ f\]
this is differentiable by chain rule since $f$ and $\Pi^{i}$ are differentiable $\forall i =1 , \dots , m$
\begin{align*}
\Rightarrow Df^{i} &= D\Pi^{i}(a) \cdot Df(a)
\shortintertext{$D\Pi^{i} = \Pi^{i}$}
\Rightarrow Df^{i} &= \Pi^{i}(a) \cdot Df(a)
\end{align*}
Now assume the all $f^{i}$ are differentiable at $a$ $\forall i=1, \dots , m$
\begin{align*}
&f(a+h) - f(a) -(Df^{1}(a)(h), \dots , Df^{m}(a)(h))\\
 &= (f^{1}(a+h), \dots , f^{m}(a+h)) - (f^{1}, \dots, f^{m}) - (Df^{1}*(a)(h), \dots , Df^{m}(a)(h))\\
&=(f^{1}(a+h) -f^{1}(a) - df^{1}(a) , \dots , f^{m}(a+h) -f^{m}(a) - df^{m}(a))
\end{align*}
So
\begin{align*}
 &\frac{|f(a+h) - f(a) -(Df^{1}(a)(h), \dots , Df^{m}(a)(h))|}{|h|} \\
&\leq \frac{|f^{1}(a+h) -f^{1}(a) - df^{1}(a)|}{|h|} , \dots ,\frac{| f^{m}(a+h) -f^{m}(a) - df^{m}(a)|}{|h|} \rightarrow 0
\end{align*}
\end{proof}
\end{theorem} 

\begin{remark}
If $T,S:\RR^{n} \rightarrow \RR^{m}$ are linear then $(T +S):\RR^{n} \rightarrow \RR^{m}, (T+S)(x) = T(x) + S(x)$ is linear.\\
If $\lambda \in \RR$ then $(\lambda T):\RR^{n} \rightarrow \RR^{m}, (\lambda T)(x) = \lambda \cdot T(x)$ is also linear.
\end{remark}

\end{document}
